{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from functions import *\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import clear_session\n",
    "clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperparameters as hp\n",
    "\n",
    "\n",
    "directory_path = 'LA/ASVspoof2019_LA_train/flac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING TRAIN DATASET FROM FILE\n",
      "WARNING:tensorflow:From C:\\Users\\Aditya Ahuja\\AppData\\Local\\Temp\\ipykernel_22624\\1608166851.py:8: load (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.load(...)` instead.\n",
      "TRAIN DATASET LOADED FROM FILE\n",
      "NUMBER OF ENTRIES IN TRAINING DATASET:  794\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# add a if statement that if train_dataset.pkl exists, load it, else create it\n",
    "\n",
    "if os.path.exists('dataset_pickle_dumps/train_dataset_dumped.pkl'):\n",
    "    print(\"LOADING TRAIN DATASET FROM FILE\")\n",
    "    dataset = tf.data.experimental.load('dataset_pickle_dumps/train_dataset_dumped.pkl')\n",
    "    print(\"TRAIN DATASET LOADED FROM FILE\")\n",
    "    \n",
    "else:\n",
    "\n",
    "    with open('train_preprocessed.txt', 'r') as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "    file_names = []\n",
    "    labels = []\n",
    "\n",
    "    subset_size = 1000\n",
    "    for line in data:\n",
    "        if subset_size == 0:\n",
    "            break\n",
    "    #  subset_size -= 1\n",
    "        file_name, label = line.split()\n",
    "        file_names.append(file_name)\n",
    "        labels.append(int(label))\n",
    "\n",
    "    tensors = []\n",
    "\n",
    "    ctr = 0 \n",
    "\n",
    "\n",
    "    for file_name in file_names:\n",
    "        ctr+=1\n",
    "        if ctr % 200 == 0:\n",
    "            print(f\"PROGRESS: {ctr}/{len(file_names)}\")\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        signal, sample_rate = read_flac_file(file_path)\n",
    "        lfcc_features = extract_lfcc(signal, sample_rate)\n",
    "        tensor = tf.convert_to_tensor(lfcc_features)\n",
    "        tensor = tf.expand_dims(tensor, axis=0)\n",
    "        tensors.append(tensor[0])\n",
    "        \n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((tensors, labels))\n",
    "\n",
    "    dataset = dataset.shuffle(buffer_size=len(tensors)).batch(32)\n",
    "\n",
    "    tf.data.experimental.save(dataset, 'dataset_pickle_dumps/train_dataset_dumped.pkl')\n",
    "\n",
    "    print(\"TRAIN DATASET DUMPED TO FILE\")\n",
    "\n",
    "print(\"NUMBER OF ENTRIES IN TRAINING DATASET: \", len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1, 10, 300)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 1, 10, 32)    9632        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 1, 10, 32)    9248        ['conv2d_52[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 1, 10, 32)   128         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4 (Gl  (None, 32)          0           ['batch_normalization_72[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1, 32)     0           ['global_average_pooling2d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 1, 1, 2)      66          ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 1, 1, 32)     96          ['conv2d_54[0][0]']              \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 1, 10, 32)    0           ['batch_normalization_72[0][0]', \n",
      "                                                                  'conv2d_55[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 1, 10, 32)    1056        ['multiply[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 1, 10, 32)    0           ['conv2d_56[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 1, 10, 32)   128         ['dropout_24[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 1, 10, 32)    0           ['batch_normalization_73[0][0]', \n",
      "                                                                  'conv2d_52[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 1, 10, 192)   6336        ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 1, 10, 192)  768         ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " depthwise_conv2d_24 (Depthwise  (None, 1, 10, 192)  1920        ['batch_normalization_74[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 1, 10, 192)  768         ['depthwise_conv2d_24[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 192)         0           ['batch_normalization_75[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 1, 192)    0           ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 1, 1, 12)     2316        ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 1, 1, 192)    2496        ['conv2d_58[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 1, 10, 192)   0           ['batch_normalization_75[0][0]', \n",
      "                                                                  'conv2d_59[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 1, 10, 32)    6176        ['multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 1, 10, 32)    0           ['conv2d_60[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 1, 10, 32)   128         ['dropout_25[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 1, 10, 32)    0           ['batch_normalization_76[0][0]', \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 1, 10, 288)   9504        ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 1, 10, 288)  1152        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " depthwise_conv2d_25 (Depthwise  (None, 1, 10, 288)  2880        ['batch_normalization_78[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 1, 10, 288)  1152        ['depthwise_conv2d_25[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6 (Gl  (None, 288)         0           ['batch_normalization_79[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1, 1, 288)    0           ['global_average_pooling2d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 1, 1, 18)     5202        ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 1, 1, 288)    5472        ['conv2d_63[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 1, 10, 288)   0           ['batch_normalization_79[0][0]', \n",
      "                                                                  'conv2d_64[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 1, 10, 48)    13872       ['multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 1, 10, 48)    0           ['conv2d_65[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 1, 10, 48)    1584        ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 1, 10, 48)   192         ['dropout_26[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 1, 10, 48)   192         ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 1, 10, 48)    0           ['batch_normalization_80[0][0]', \n",
      "                                                                  'batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 1, 10, 288)   14112       ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 1, 10, 288)  1152        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " depthwise_conv2d_26 (Depthwise  (None, 1, 10, 288)  2880        ['batch_normalization_81[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 1, 10, 288)  1152        ['depthwise_conv2d_26[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7 (Gl  (None, 288)         0           ['batch_normalization_82[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 1, 1, 288)    0           ['global_average_pooling2d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 1, 1, 18)     5202        ['reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 1, 1, 288)    5472        ['conv2d_67[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 1, 10, 288)   0           ['batch_normalization_82[0][0]', \n",
      "                                                                  'conv2d_68[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 1, 10, 48)    13872       ['multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 1, 10, 48)    0           ['conv2d_69[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 1, 10, 48)   192         ['dropout_27[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 1, 10, 48)    0           ['batch_normalization_83[0][0]', \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 1, 10, 384)   18816       ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 1, 10, 384)  1536        ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " depthwise_conv2d_27 (Depthwise  (None, 1, 10, 384)  3840        ['batch_normalization_85[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 1, 10, 384)  1536        ['depthwise_conv2d_27[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 384)         0           ['batch_normalization_86[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 1, 1, 384)    0           ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 1, 1, 24)     9240        ['reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 1, 10, 2)     5402        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 1, 1, 384)    9600        ['conv2d_72[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 1, 10, 2)    8           ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 1, 10, 384)   0           ['batch_normalization_86[0][0]', \n",
      "                                                                  'conv2d_73[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 1, 10, 2)     38          ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 1, 10, 64)    24640       ['multiply_4[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 1, 10, 2)    8           ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 1, 10, 64)    0           ['conv2d_74[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 1, 10, 64)    3136        ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 1, 10, 4)     76          ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 1, 10, 64)   256         ['dropout_28[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 1, 10, 64)   256         ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 1, 10, 4)    16          ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 1, 10, 64)    0           ['batch_normalization_87[0][0]', \n",
      "                                                                  'batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 1, 10, 4)     148         ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 1, 10, 384)   24960       ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 1, 10, 4)    16          ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 1, 10, 384)  1536        ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 1, 10, 8)     296         ['batch_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " depthwise_conv2d_28 (Depthwise  (None, 1, 10, 384)  3840        ['batch_normalization_88[0][0]'] \n",
      " Conv2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 1, 10, 8)    32          ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 1, 10, 384)  1536        ['depthwise_conv2d_28[0][0]']    \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 1, 10, 8)     584         ['batch_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_9 (Gl  (None, 384)         0           ['batch_normalization_89[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, 1, 10, 8)    32          ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 1, 1, 384)    0           ['global_average_pooling2d_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 1, 10, 16)    1168        ['batch_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 1, 1, 24)     9240        ['reshape_5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, 1, 10, 16)   64          ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 1, 1, 384)    9600        ['conv2d_76[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 1, 10, 16)    2320        ['batch_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 1, 10, 384)   0           ['batch_normalization_89[0][0]', \n",
      "                                                                  'conv2d_77[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, 1, 10, 16)   64          ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 1, 10, 64)    24640       ['multiply_5[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, 1, 10, 16)   64          ['batch_normalization_98[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, 1, 10, 64)    0           ['conv2d_78[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 1, 10, 16)    272         ['batch_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 1, 10, 64)   256         ['dropout_29[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 1, 10, 16)    0           ['conv2d_88[0][0]']              \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 1, 10, 64)    0           ['batch_normalization_90[0][0]', \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 1, 10, 1)     17          ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 1, 10, 1280)  83200       ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, 1, 10, 1)    4           ['conv2d_89[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)           (None, 1, 10, 1280)  0           ['conv2d_79[0][0]']              \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 1, 10, 1)     0           ['batch_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling2d_10 (G  (None, 1280)        0           ['dropout_30[0][0]']             \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling2d_11 (G  (None, 1)           0           ['activation_44[0][0]']          \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            1281        ['global_average_pooling2d_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 1)            0           ['global_average_pooling2d_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 1)            0           ['dense_3[0][0]',                \n",
      "                                                                  'reshape_6[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 1)           0           ['dense_3[0][0]',                \n",
      " da)                                                              'tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 370,072\n",
      "Trainable params: 362,910\n",
      "Non-trainable params: 7,162\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# def se_block(input_tensor, ratio=16):\n",
    "#     filters = input_tensor.shape[-1]\n",
    "#     se = layers.GlobalAveragePooling2D()(input_tensor)\n",
    "#     se = layers.Reshape((1, 1, filters))(se)\n",
    "#     se = layers.Conv2D(filters // ratio, 1, activation='relu')(se)\n",
    "#     se = layers.Conv2D(filters, 1, activation='sigmoid')(se)\n",
    "#     return layers.Multiply()([input_tensor, se])\n",
    "\n",
    "# def mb_conv1_block(input_tensor, kernel_size=3, filters=16, dropout_rate=0.2):\n",
    "#     x = layers.Conv2D(filters, (kernel_size, kernel_size), padding='same')(input_tensor)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = se_block(x)\n",
    "#     x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
    "#     x = layers.Dropout(dropout_rate)(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     return layers.Add()([x, input_tensor])\n",
    "\n",
    "# def mb_conv6_block(input_tensor, kernel_size=3, filters=16, dropout_rate=0.2):\n",
    "#     input_filters = input_tensor.shape[-1]\n",
    "#     if input_filters != filters:\n",
    "#         shortcut = layers.Conv2D(filters, (1, 1), padding='same')(input_tensor)\n",
    "#         shortcut = layers.BatchNormalization()(shortcut)\n",
    "#     else:\n",
    "#         shortcut = input_tensor\n",
    "\n",
    "#     x = layers.Conv2D(filters * 6, (1, 1), padding='same')(input_tensor)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.DepthwiseConv2D((kernel_size, kernel_size), padding='same')(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = se_block(x)\n",
    "#     x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
    "#     x = layers.Dropout(dropout_rate)(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     return layers.Add()([x, shortcut])\n",
    "\n",
    "# def BasicBlock(input_tensor, c_in, c_out):\n",
    "#     x = layers.Conv2D(c_out, (3, 3), padding='same')(input_tensor)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Conv2D(c_out, (3, 3), padding='same')(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     return x\n",
    "\n",
    "# def attention_branch(input_tensor):\n",
    "#     x = BasicBlock(input_tensor, 1, 2)\n",
    "#     x = BasicBlock(x, 2, 4)\n",
    "#     x = BasicBlock(x, 4, 8)\n",
    "#     x = BasicBlock(x, 8, 16)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Conv2D(16, (1, 1), padding='same')(x)\n",
    "#     x = layers.ReLU()(x)\n",
    "#     x = layers.Conv2D(1, (1, 1), padding='same')(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     A = layers.Activation('sigmoid')(x)\n",
    "#     return A\n",
    "\n",
    "# def EfficientNet_A0_with_attention(input_shape=(1, hp.F, hp.T), dropout_rate=0.2):\n",
    "#     inputs = layers.Input(shape=input_shape)\n",
    "#     x = layers.Conv2D(32, (1, 1), padding='same')(inputs)\n",
    "#     x = mb_conv1_block(x, filters=32, dropout_rate=dropout_rate)\n",
    "#     x = mb_conv6_block(x, filters=32, dropout_rate=dropout_rate)\n",
    "#     x = mb_conv6_block(x, filters=48, dropout_rate=dropout_rate)\n",
    "#     x = mb_conv6_block(x, filters=48, dropout_rate=dropout_rate)\n",
    "#     x = mb_conv6_block(x, filters=64, dropout_rate=dropout_rate)\n",
    "#     x = mb_conv6_block(x, filters=64, dropout_rate=dropout_rate)\n",
    "#     x = layers.Conv2D(1280, (1, 1), padding='same')(x)\n",
    "#     x = layers.Dropout(dropout_rate)(x)\n",
    "#     R = layers.GlobalAveragePooling2D()(x)\n",
    "#     R_output = layers.Dense(1, activation='sigmoid')(R)\n",
    "#     A = attention_branch(inputs)\n",
    "#     A_adjusted = layers.GlobalAveragePooling2D()(A)\n",
    "#     A_adjusted = layers.Reshape((1,))(A_adjusted)\n",
    "#     combined_output = R_output + R_output * A_adjusted\n",
    "#     model = models.Model(inputs, combined_output)\n",
    "#     return model\n",
    "\n",
    "# # Adding regularization \n",
    "\n",
    "# from keras import regularizers, losses\n",
    "\n",
    "# eer_prev = 1\n",
    "\n",
    "# def custom_loss(y_true, y_pred):\n",
    "#     bce = losses.binary_crossentropy(y_true, y_pred)\n",
    "#     reg = regularizers.l2(0.06)\n",
    "#     regularization = tf.reduce_sum(reg(y_pred)) * tf.reduce_max(y_pred)\n",
    "#     loss = bce + regularization\n",
    "#     return (loss * (eer_prev**2)) * 1000\n",
    "\n",
    "\n",
    "# # shape: (1xFxT)\n",
    "# input_shape = (1, hp.F, hp.T)\n",
    "# model = EfficientNet_A0_with_attention(input_shape=input_shape)\n",
    "# model.compile(optimizer='adam', loss= custom_loss, metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "\n",
    "def se_block(input_tensor, ratio=16):\n",
    "    filters = input_tensor.shape[-1]\n",
    "    se = layers.GlobalAveragePooling2D()(input_tensor)\n",
    "    se = layers.Reshape((1, 1, filters))(se)\n",
    "    se = layers.Conv2D(filters // ratio, 1, activation='relu')(se)\n",
    "    se = layers.Conv2D(filters, 1, activation='sigmoid')(se)\n",
    "    return layers.Multiply()([input_tensor, se])\n",
    "\n",
    "def mb_conv1_block(input_tensor, kernel_size=3, filters=16, dropout_rate=0.2):\n",
    "    x = layers.Conv2D(filters, (kernel_size, kernel_size), padding='same')(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = se_block(x)\n",
    "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return layers.Add()([x, input_tensor])\n",
    "\n",
    "def mb_conv6_block(input_tensor, kernel_size=3, filters=16, dropout_rate=0.2):\n",
    "    input_filters = input_tensor.shape[-1]\n",
    "    if input_filters != filters:\n",
    "        shortcut = layers.Conv2D(filters, (1, 1), padding='same')(input_tensor)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "    else:\n",
    "        shortcut = input_tensor\n",
    "\n",
    "    x = layers.Conv2D(filters * 6, (1, 1), padding='same')(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.DepthwiseConv2D((kernel_size, kernel_size), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = se_block(x)\n",
    "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return layers.Add()([x, shortcut])\n",
    "\n",
    "def BasicBlock(input_tensor, c_in, c_out):\n",
    "    x = layers.Conv2D(c_out, (3, 3), padding='same')(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(c_out, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def attention_branch(input_tensor):\n",
    "    x = BasicBlock(input_tensor, 1, 2)\n",
    "    x = BasicBlock(x, 2, 4)\n",
    "    x = BasicBlock(x, 4, 8)\n",
    "    x = BasicBlock(x, 8, 16)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(16, (1, 1), padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(1, (1, 1), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    A = layers.Activation('sigmoid')(x)\n",
    "    return A\n",
    "\n",
    "def EfficientNet_A0_with_attention(input_shape=(1, hp.F, hp.T), dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (1, 1), padding='same')(inputs)\n",
    "    x = mb_conv1_block(x, filters=32, dropout_rate=dropout_rate)\n",
    "    x = mb_conv6_block(x, filters=32, dropout_rate=dropout_rate)\n",
    "    x = mb_conv6_block(x, filters=48, dropout_rate=dropout_rate)\n",
    "    x = mb_conv6_block(x, filters=48, dropout_rate=dropout_rate)\n",
    "    x = mb_conv6_block(x, filters=64, dropout_rate=dropout_rate)\n",
    "    x = mb_conv6_block(x, filters=64, dropout_rate=dropout_rate)\n",
    "    x = layers.Conv2D(1280, (1, 1), padding='same')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    R = layers.GlobalAveragePooling2D()(x)\n",
    "    R_output = layers.Dense(1, activation='sigmoid')(R)\n",
    "    A = attention_branch(inputs)\n",
    "    A_adjusted = layers.GlobalAveragePooling2D()(A)\n",
    "    A_adjusted = layers.Reshape((1,))(A_adjusted)\n",
    "    combined_output = R_output + R_output * A_adjusted\n",
    "    model = models.Model(inputs, combined_output)\n",
    "    return model\n",
    "\n",
    "# Adding regularization \n",
    "\n",
    "from keras import regularizers, losses\n",
    "\n",
    "eer_prev = 1\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    bce = losses.binary_crossentropy(y_true, y_pred)\n",
    "    reg = regularizers.l2(0.06)\n",
    "    regularization = tf.reduce_sum(reg(y_pred)) * tf.reduce_max(y_pred)\n",
    "    loss = bce + regularization\n",
    "    return (loss * (eer_prev**2)) * 1000\n",
    "\n",
    "\n",
    "# shape: (1xFxT)\n",
    "input_shape = (1, hp.F, hp.T)\n",
    "model = EfficientNet_A0_with_attention(input_shape=input_shape)\n",
    "model.compile(optimizer='adam', loss= custom_loss, metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, ratio=16, **kwargs):\n",
    "        super(SEBlock, self).__init__(**kwargs)\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.filters = input_shape[-1]\n",
    "        self.reshape = layers.Reshape((1, 1, self.filters))\n",
    "        self.conv1 = layers.Conv2D(self.filters // self.ratio, 1, activation='relu',  data_format='channels_last')\n",
    "        self.conv2 = layers.Conv2D(self.filters, 1, activation='sigmoid',  data_format='channels_last')\n",
    "        self.multiply = layers.Multiply()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        se = layers.GlobalAveragePooling2D()(inputs)\n",
    "        se = self.reshape(se)\n",
    "        se = self.conv1(se)\n",
    "        se = self.conv2(se)\n",
    "        return self.multiply([inputs, se])\n",
    "\n",
    "\n",
    "class MBConv1Block (tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel_size=3, filters=16, dropout_rate=0.2):\n",
    "        super(MBConv1Block, self).__init__()\n",
    "        self.dconv = tf.keras.layers.DepthwiseConv2D((kernel_size, kernel_size), padding='same',  data_format='channels_last')\n",
    "        self.swish1 = tf.keras.layers.Activation('swish')\n",
    "        self.batch_norm1 = tf.keras.layers.BatchNormalization()\n",
    "        self.se = SEBlock(ratio = 16)\n",
    "        self.conv = tf.keras.layers.Conv2D(filters, (1, 1), padding='same', activation=tf.keras.activations.sigmoid,  data_format='channels_last')\n",
    "        self.batch_norm1 = tf.keras.layers.BatchNormalization()\n",
    "        self.batch_norm2 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "    def call(self, input):\n",
    "        output = self.dconv(input)\n",
    "        output = self.batch_norm1(output)\n",
    "        output = self.swish1(output)\n",
    "        output = self.se(output)\n",
    "        output = self.conv(output)\n",
    "        output = self.batch_norm2(output)\n",
    "        return output\n",
    "    \n",
    "class MBConv6Block (tf.keras.layers.Layer):\n",
    "    def __init__(self, kernel_size=3, filters=16, dropout_rate=0.2):\n",
    "        super(MBConv6Block, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters * 6, (1, 1), padding='same', activation=tf.keras.activations.relu,  data_format='channels_last')\n",
    "        self.batch_norm1 = tf.keras.layers.BatchNormalization()\n",
    "        self.swish1 = tf.keras.layers.Activation('swish')\n",
    "        self.dconv = tf.keras.layers.DepthwiseConv2D((kernel_size, kernel_size), padding='same')\n",
    "        self.swish2 = tf.keras.layers.Activation('swish')\n",
    "        self.batch_norm2 = tf.keras.layers.BatchNormalization()\n",
    "        self.se = SEBlock(ratio = 16)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters, (1, 1), padding='same')\n",
    "        self.batch_norm3 = tf.keras.layers.BatchNormalization()\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.input_conv = tf.keras.layers.Conv2D(self.filters, (1, 1), padding='same')\n",
    "        \n",
    "    def call(self, input):\n",
    "        input_processed = self.input_conv(input)\n",
    "        output = self.conv1(input)\n",
    "        output = self.batch_norm1(output)\n",
    "        output = self.swish1(output)\n",
    "        output = self.dconv(output)\n",
    "        output = self.swish2(output)\n",
    "        output = self.batch_norm2(output)\n",
    "        output = self.se(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.batch_norm3(output)\n",
    "        output = self.dropout(output)\n",
    "        output = output + input_processed\n",
    "        return output\n",
    "\n",
    "    \n",
    "\n",
    "class BasicBlock (tf.keras.layers.Layer):\n",
    "    def __init__(self,C_in,C_out):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(C_out, (3, 3), padding='same', data_format='channels_last')\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(C_out, (3, 3), padding='same', data_format='channels_last')\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "    def call(self, input):\n",
    "        input = self.conv1(input)\n",
    "        input = self.bn1(input)\n",
    "        input = self.conv2(input)\n",
    "        input = self.bn2(input)\n",
    "        return input\n",
    "    \n",
    "\n",
    "class AttentionBranch (tf.keras.Model):\n",
    "    def __init__(self,):\n",
    "        super(AttentionBranch, self).__init__()\n",
    "        self.bb1 = BasicBlock(1,2)\n",
    "        self.bb2 = BasicBlock(2,4)\n",
    "        self.bb3 = BasicBlock(4,8)\n",
    "        self.bb4 = BasicBlock(8,16)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(16, (1, 1), padding='same', data_format='channels_last')\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        self.ab_output_conv = tf.keras.layers.Conv2D(2, (1, 1), padding='same', data_format='channels_last')\n",
    "        self.ab_output_gap = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.ab_output_softmax = tf.keras.layers.Softmax()\n",
    "        self.attention_map_conv = tf.keras.layers.Conv2D(1, (1, 1), padding='same', data_format='channels_last')\n",
    "        self.attention_map_bn = tf.keras.layers.BatchNormalization()\n",
    "        self.attention_map_sigmoid = tf.keras.layers.Activation('sigmoid')\n",
    "    \n",
    "    def call (self, input):\n",
    "        output = self.bb1(input)\n",
    "        output = self.bb2(output)\n",
    "        output = self.bb3(output)\n",
    "        output = self.bb4(output)\n",
    "        output = self.bn1(output)\n",
    "        output = self.conv1(output)\n",
    "        output = self.relu(output)\n",
    "        ab_output =  self.ab_output_conv(output)\n",
    "        ab_output = self.ab_output_gap(ab_output)\n",
    "        ab_output = self.ab_output_softmax(ab_output)\n",
    "        attention_map = self.attention_map_conv(output)\n",
    "        attention_map = self.attention_map_bn(attention_map)\n",
    "        attention_map = self.attention_map_sigmoid(attention_map)\n",
    "        return ab_output, attention_map\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetA0(tf.keras.Model):\n",
    "    def __init__(self, output_dim = 2, dropout=0.2):\n",
    "        super(EfficientNetA0, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, (1, 1), padding='same', data_format='channels_last')\n",
    "        self.mbconv1_1 = MBConv1Block(filters = 32, dropout_rate=dropout)\n",
    "        self.mbconv6_1 = MBConv6Block(filters = 32, dropout_rate=dropout)\n",
    "        self.mbconv6_2 = MBConv6Block(filters = 48, dropout_rate=dropout)\n",
    "        self.mbconv6_3 = MBConv6Block(filters = 48, dropout_rate=dropout)\n",
    "        self.mbconv6_4 = MBConv6Block(filters = 64, dropout_rate=dropout)\n",
    "        self.mbconv6_5 = MBConv6Block(filters = 64, dropout_rate=dropout)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(256, (1, 1), padding='same', data_format='channels_last')\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        self.global_avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.dense = tf.keras.layers.Dense(output_dim)\n",
    "         \n",
    "    def call(self, input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.mbconv1_1(output)\n",
    "        output = self.mbconv6_1(output)\n",
    "        output = self.mbconv6_2(output)\n",
    "        output = self.mbconv6_3(output)\n",
    "        output = self.mbconv6_4(output)\n",
    "        output = self.mbconv6_5(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.dropout(output)\n",
    "        output = self.global_avg_pool(output)\n",
    "        output = self.dense(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EABNModel(tf.keras.Model):\n",
    "    def __init__(self, dropout=0.2):\n",
    "        super(EABNModel, self).__init__()\n",
    "        self.efficientnet = EfficientNetA0(dropout=dropout)\n",
    "        self.attention_branch = AttentionBranch()\n",
    "    \n",
    "    def call(self, input):\n",
    "        ab_output, attention_map = self.attention_branch(input)\n",
    "        perception_input = input * attention_map\n",
    "        perception_input = perception_input + input\n",
    "        perception_output = self.efficientnet(perception_input)\n",
    "        return ab_output, perception_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"eabn_model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficient_net_a0_11 (Effici  multiple                 280740    \n",
      " entNetA0)                                                       \n",
      "                                                                 \n",
      " attention_branch_6 (Attenti  multiple                 5281      \n",
      " onBranch)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 286,021\n",
      "Trainable params: 279,083\n",
      "Non-trainable params: 6,938\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_model = EABNModel()\n",
    "test_model.build((None,hp.F, hp.T,1))\n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlabels\\n\\none_ctr = 0 \\nzero_ctr = 0 \\n\\nfor i in labels : \\n    if i == 0: \\n        zero_ctr +=1\\n    else : \\n        one_ctr +=1\\n\\nprint(one_ctr , zero_ctr)\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "labels\n",
    "\n",
    "one_ctr = 0 \n",
    "zero_ctr = 0 \n",
    "\n",
    "for i in labels : \n",
    "    if i == 0: \n",
    "        zero_ctr +=1\n",
    "    else : \n",
    "        one_ctr +=1\n",
    "\n",
    "print(one_ctr , zero_ctr)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 03:18:40.935886: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793/794 [============================>.] - ETA: 0s - loss: 960.2877 - accuracy: 0.6295Epoch 1:\n",
      "Accuracy for class 0 (bonafide): 0.8864341085271318\n",
      "Accuracy for class 1 (spoofed): 0.8862280701754386\n",
      "EER: 0.11356589147286822\n",
      "794/794 [==============================] - 43s 39ms/step - loss: 960.2493 - accuracy: 0.6295\n",
      "Epoch 2/30\n",
      "791/794 [============================>.] - ETA: 0s - loss: 923.6325 - accuracy: 0.8293Epoch 2:\n",
      "Accuracy for class 0 (bonafide): 0.8461240310077519\n",
      "Accuracy for class 1 (spoofed): 0.8471491228070176\n",
      "EER: 0.15387596899224806\n",
      "794/794 [==============================] - 30s 38ms/step - loss: 923.6179 - accuracy: 0.8294\n",
      "Epoch 3/30\n",
      "793/794 [============================>.] - ETA: 0s - loss: 913.3525 - accuracy: 0.8633Epoch 3:\n",
      "Accuracy for class 0 (bonafide): 0.9321705426356589\n",
      "Accuracy for class 1 (spoofed): 0.9310087719298246\n",
      "EER: 0.06821705426356589\n",
      "794/794 [==============================] - 31s 39ms/step - loss: 913.3143 - accuracy: 0.8634\n",
      "Epoch 4/30\n",
      "793/794 [============================>.] - ETA: 0s - loss: 908.0572 - accuracy: 0.8845Epoch 4:\n",
      "Accuracy for class 0 (bonafide): 0.9418604651162791\n",
      "Accuracy for class 1 (spoofed): 0.9396929824561403\n",
      "EER: 0.05852713178294574\n",
      "794/794 [==============================] - 30s 38ms/step - loss: 908.0206 - accuracy: 0.8845\n",
      "Epoch 5/30\n",
      "791/794 [============================>.] - ETA: 0s - loss: 904.8859 - accuracy: 0.8966Epoch 5:\n",
      "Accuracy for class 0 (bonafide): 0.9364341085271318\n",
      "Accuracy for class 1 (spoofed): 0.935921052631579\n",
      "EER: 0.06395348837209303\n",
      "794/794 [==============================] - 30s 38ms/step - loss: 904.9077 - accuracy: 0.8965\n",
      "Epoch 6/30\n",
      "793/794 [============================>.] - ETA: 0s - loss: 903.2334 - accuracy: 0.9003Epoch 6:\n",
      "Accuracy for class 0 (bonafide): 0.9387596899224806\n",
      "Accuracy for class 1 (spoofed): 0.9378070175438596\n",
      "EER: 0.06162790697674419\n",
      "794/794 [==============================] - 32s 41ms/step - loss: 903.1926 - accuracy: 0.9003\n",
      "Epoch 7/30\n",
      "792/794 [============================>.] - ETA: 0s - loss: 901.0350 - accuracy: 0.9041Epoch 7:\n",
      "Accuracy for class 0 (bonafide): 0.9189922480620155\n",
      "Accuracy for class 1 (spoofed): 0.9192105263157895\n",
      "EER: 0.0810077519379845\n",
      "794/794 [==============================] - 33s 41ms/step - loss: 901.0552 - accuracy: 0.9040\n",
      "Epoch 8/30\n",
      "790/794 [============================>.] - ETA: 0s - loss: 897.0267 - accuracy: 0.9153Epoch 8:\n",
      "Accuracy for class 0 (bonafide): 0.9468992248062016\n",
      "Accuracy for class 1 (spoofed): 0.9455263157894737\n",
      "EER: 0.05310077519379845\n",
      "794/794 [==============================] - 33s 42ms/step - loss: 897.0294 - accuracy: 0.9153\n",
      "Epoch 9/30\n",
      "791/794 [============================>.] - ETA: 0s - loss: 896.9011 - accuracy: 0.9159Epoch 9:\n",
      "Accuracy for class 0 (bonafide): 0.9488372093023256\n",
      "Accuracy for class 1 (spoofed): 0.9494298245614035\n",
      "EER: 0.05116279069767442\n",
      "794/794 [==============================] - 32s 40ms/step - loss: 896.9329 - accuracy: 0.9159\n",
      "Epoch 10/30\n",
      "794/794 [==============================] - ETA: 0s - loss: 894.6456 - accuracy: 0.9230Epoch 10:\n",
      "Accuracy for class 0 (bonafide): 0.9441860465116279\n",
      "Accuracy for class 1 (spoofed): 0.9444736842105264\n",
      "EER: 0.05581395348837209\n",
      "794/794 [==============================] - 33s 42ms/step - loss: 894.6456 - accuracy: 0.9230\n",
      "Epoch 11/30\n",
      "792/794 [============================>.] - ETA: 0s - loss: 891.7125 - accuracy: 0.9269Epoch 11:\n",
      "Accuracy for class 0 (bonafide): 0.9507751937984497\n",
      "Accuracy for class 1 (spoofed): 0.9504385964912281\n",
      "EER: 0.04961240310077519\n",
      "794/794 [==============================] - 33s 42ms/step - loss: 891.7326 - accuracy: 0.9269\n",
      "Epoch 12/30\n",
      "794/794 [==============================] - ETA: 0s - loss: 888.8487 - accuracy: 0.9319Epoch 12:\n",
      "Accuracy for class 0 (bonafide): 0.95\n",
      "Accuracy for class 1 (spoofed): 0.9496052631578947\n",
      "EER: 0.050387596899224806\n",
      "794/794 [==============================] - 32s 41ms/step - loss: 888.8487 - accuracy: 0.9319\n",
      "Epoch 13/30\n",
      "792/794 [============================>.] - ETA: 0s - loss: 887.5151 - accuracy: 0.9368Epoch 13:\n",
      "Accuracy for class 0 (bonafide): 0.9562015503875969\n",
      "Accuracy for class 1 (spoofed): 0.9560526315789474\n",
      "EER: 0.043798449612403104\n",
      "794/794 [==============================] - 33s 42ms/step - loss: 887.5339 - accuracy: 0.9368\n",
      "Epoch 14/30\n",
      "794/794 [==============================] - ETA: 0s - loss: 887.9367 - accuracy: 0.9326Epoch 14:\n",
      "Accuracy for class 0 (bonafide): 0.9441860465116279\n",
      "Accuracy for class 1 (spoofed): 0.9446929824561403\n",
      "EER: 0.05581395348837209\n",
      "794/794 [==============================] - 32s 40ms/step - loss: 887.9367 - accuracy: 0.9326\n",
      "Epoch 15/30\n",
      "792/794 [============================>.] - ETA: 0s - loss: 887.3885 - accuracy: 0.9358Epoch 15:\n",
      "Accuracy for class 0 (bonafide): 0.9608527131782946\n",
      "Accuracy for class 1 (spoofed): 0.9598245614035088\n",
      "EER: 0.03953488372093023\n",
      "794/794 [==============================] - 33s 42ms/step - loss: 887.4100 - accuracy: 0.9357\n",
      "Epoch 16/30\n",
      "794/794 [==============================] - ETA: 0s - loss: 883.5200 - accuracy: 0.9428Epoch 16:\n",
      "Accuracy for class 0 (bonafide): 0.9624031007751938\n",
      "Accuracy for class 1 (spoofed): 0.9620614035087719\n",
      "EER: 0.03798449612403101\n",
      "794/794 [==============================] - 33s 42ms/step - loss: 883.5200 - accuracy: 0.9428\n",
      "Epoch 17/30\n",
      "790/794 [============================>.] - ETA: 0s - loss: 883.0021 - accuracy: 0.9445Epoch 17:\n",
      "Accuracy for class 0 (bonafide): 0.963953488372093\n",
      "Accuracy for class 1 (spoofed): 0.9635964912280702\n",
      "EER: 0.03643410852713178\n",
      "794/794 [==============================] - 32s 41ms/step - loss: 883.0285 - accuracy: 0.9445\n",
      "Epoch 18/30\n",
      "793/794 [============================>.] - ETA: 0s - loss: 884.2705 - accuracy: 0.9384Epoch 18:\n",
      "Accuracy for class 0 (bonafide): 0.9589147286821705\n",
      "Accuracy for class 1 (spoofed): 0.9588157894736842\n",
      "EER: 0.04108527131782946\n",
      "794/794 [==============================] - 34s 43ms/step - loss: 884.2379 - accuracy: 0.9384\n",
      "Epoch 19/30\n",
      "790/794 [============================>.] - ETA: 0s - loss: 880.9839 - accuracy: 0.9460Epoch 19:\n",
      "Accuracy for class 0 (bonafide): 0.9670542635658915\n",
      "Accuracy for class 1 (spoofed): 0.9667543859649123\n",
      "EER: 0.03333333333333333\n",
      "794/794 [==============================] - 32s 41ms/step - loss: 881.0133 - accuracy: 0.9460\n",
      "Epoch 20/30\n",
      "794/794 [==============================] - ETA: 0s - loss: 880.6083 - accuracy: 0.9460Epoch 20:\n",
      "Accuracy for class 0 (bonafide): 0.9705426356589147\n",
      "Accuracy for class 1 (spoofed): 0.9703508771929824\n",
      "EER: 0.02945736434108527\n",
      "794/794 [==============================] - 34s 42ms/step - loss: 880.6083 - accuracy: 0.9460\n"
     ]
    }
   ],
   "source": [
    "# from keras.callbacks import Callback\n",
    "# from scipy.special import softmax\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import roc_curve\n",
    "\n",
    "# class ClassWiseAccuracy(Callback):\n",
    "#     def __init__(self, dataset):\n",
    "#         super().__init__()\n",
    "#         self.dataset = dataset\n",
    "\n",
    "#     def on_epoch_end(self, n_epochs_training, logs=None):\n",
    "#         y_true = []\n",
    "#         y_pred = []\n",
    "#         for x, y in self.dataset:\n",
    "#             y_true.extend(y.numpy())\n",
    "#             predictions = self.model.predict(x, verbose=0)\n",
    "#             if predictions.shape[1] == 1:\n",
    "#                 predictions = np.hstack([1 - predictions, predictions])\n",
    "#             predictions = softmax(predictions, axis=-1)\n",
    "#             y_pred.extend((predictions[:, 1] > 0.5).astype(int))\n",
    "\n",
    "#         y_true = np.array(y_true)\n",
    "#         y_pred = np.array(y_pred)\n",
    "\n",
    "#         class_0_indices = np.where(y_true == 0)\n",
    "#         class_1_indices = np.where(y_true == 1)\n",
    "\n",
    "#         class_0_accuracy = np.mean(y_true[class_0_indices] == y_pred[class_0_indices])\n",
    "#         class_1_accuracy = np.mean(y_true[class_1_indices] == y_pred[class_1_indices])\n",
    "\n",
    "#         print(f\"Epoch {n_epochs_training + 1}:\")\n",
    "#         print(f\"Accuracy for class 0 (bonafide): {class_0_accuracy}\")\n",
    "#         print(f\"Accuracy for class 1 (spoofed): {class_1_accuracy}\")\n",
    "\n",
    "#         # print EER \n",
    "#         from sklearn.metrics import roc_curve\n",
    "#         fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "#         eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "#         print(f\"EER: {eer}\")\n",
    "\n",
    "#         if eer <= 0.04 :\n",
    "#             # early stop \n",
    "#             self.model.stop_training = True \n",
    "#             return \n",
    "              \n",
    "\n",
    "# model.fit(dataset, epochs= hp.n_epochs_training, callbacks=[ClassWiseAccuracy(dataset)])\n",
    "# model.save('model.keras')\n",
    "\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "class ClassWiseAccuracy(Callback):\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_true = []\n",
    "        y_scores = []  # Store raw scores for EER calculation\n",
    "        for x, y in self.dataset:\n",
    "            y_true.extend(y.numpy())\n",
    "            predictions = self.model.predict(x, verbose=0)\n",
    "            if predictions.shape[1] == 1:\n",
    "                predictions = np.hstack([1 - predictions, predictions])\n",
    "            predictions = softmax(predictions, axis=-1)\n",
    "            y_scores.extend(predictions[:, 1])  # Use scores for the positive class\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        y_scores = np.array(y_scores)\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "        fnr = 1 - tpr\n",
    "        eer_threshold = thresholds[np.nanargmin(np.abs(fpr - fnr))]\n",
    "        eer = fpr[np.nanargmin(np.abs(fpr - fnr))]\n",
    "\n",
    "        # Apply EER threshold to make final decisions\n",
    "        y_pred = (y_scores > eer_threshold).astype(int)\n",
    "\n",
    "        class_0_indices = np.where(y_true == 0)\n",
    "        class_1_indices = np.where(y_true == 1)\n",
    "\n",
    "        class_0_accuracy = np.mean(y_true[class_0_indices] == y_pred[class_0_indices])\n",
    "        class_1_accuracy = np.mean(y_true[class_1_indices] == y_pred[class_1_indices])\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}:\")\n",
    "        print(f\"Accuracy for class 0 (bonafide): {class_0_accuracy}\")\n",
    "        print(f\"Accuracy for class 1 (spoofed): {class_1_accuracy}\")\n",
    "        print(f\"EER: {eer}\")\n",
    "\n",
    "        global eer_prev \n",
    "        eer_prev = eer\n",
    "\n",
    "        if eer <= 0.03:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "model.fit(dataset, epochs=hp.n_epochs_training, callbacks=[ClassWiseAccuracy(dataset)])\n",
    "model.save('model.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    # val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    # val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, label='Training acc')\n",
    "    # plt.plot(epochs, val_acc, label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, label='Training loss')\n",
    "    # plt.plot(epochs, val_loss, label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(model.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from pkl\n",
    "\n",
    "# model = tf.keras.models.load_model('model.keras')\n",
    "\n",
    "\n",
    "# model.evaluate(dataset_val)\n",
    "# predictions = model.predict(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING OF THE MODEL IS DONE!\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING OF THE MODEL IS DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
