{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in c:\\miniconda\\envs\\btp\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from soundfile) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\miniconda\\envs\\btp\\lib\\site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: librosa in c:\\miniconda\\envs\\btp\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from librosa) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from librosa) (1.4.1.post1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from librosa) (1.4.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from librosa) (0.59.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from librosa) (1.8.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from librosa) (4.11.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from librosa) (1.0.8)\n",
      "Requirement already satisfied: packaging in c:\\miniconda\\envs\\btp\\lib\\site-packages (from lazy-loader>=0.1->librosa) (24.0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from pooch>=1.0->librosa) (4.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from pooch>=1.0->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.4.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\miniconda\\envs\\btp\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\miniconda\\envs\\btp\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\miniconda\\envs\\btp\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install soundfile \n",
    "! pip3 install librosa\n",
    "! pip3 install matplotlib \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from functions import *\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1588"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import clear_session\n",
    "clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperparameters as hp\n",
    "directory_path = 'LA/ASVspoof2019_LA_train/flac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING TRAIN DATASET FROM FILE\n",
      "WARNING:tensorflow:From C:\\Users\\Aditya Ahuja\\AppData\\Local\\Temp\\ipykernel_21352\\1179752341.py:8: load (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.load(...)` instead.\n",
      "TRAIN DATASET LOADED FROM FILE\n",
      "NUMBER OF ENTRIES IN TRAINING DATASET:  794\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# add a if statement that if train_dataset.pkl exists, load it, else create it\n",
    "\n",
    "if os.path.exists('dataset_pickle_dumps/train_dataset_dumped.pkl'):\n",
    "    print(\"LOADING TRAIN DATASET FROM FILE\")\n",
    "    dataset = tf.data.experimental.load('dataset_pickle_dumps/train_dataset_dumped.pkl')\n",
    "    print(\"TRAIN DATASET LOADED FROM FILE\")\n",
    "    \n",
    "else:\n",
    "\n",
    "    with open('train_preprocessed.txt', 'r') as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "    file_names = []\n",
    "    labels = []\n",
    "\n",
    "    subset_size = 1000\n",
    "    for line in data:\n",
    "        if subset_size == 0:\n",
    "            break\n",
    "        # subset_size -= 1\n",
    "        file_name, label = line.split()\n",
    "        file_names.append(file_name)\n",
    "        labels.append(int(label))\n",
    "\n",
    "    tensors = []\n",
    "\n",
    "    ctr = 0 \n",
    "\n",
    "\n",
    "    for file_name in file_names:\n",
    "        ctr+=1\n",
    "        if ctr % 200 == 0:\n",
    "            print(f\"PROGRESS: {ctr}/{len(file_names)}\")\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        signal, sample_rate = read_flac_file(file_path)\n",
    "        lfcc_features = extract_lfcc(signal, sample_rate)\n",
    "        tensor = tf.convert_to_tensor(lfcc_features)\n",
    "        tensor = tf.expand_dims(tensor, axis=0)\n",
    "        tensors.append(tensor[0])\n",
    "        \n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((tensors, labels))\n",
    "\n",
    "    dataset = dataset.shuffle(buffer_size=len(tensors)).batch(32)\n",
    "\n",
    "    tf.data.experimental.save(dataset, 'dataset_pickle_dumps/train_dataset_dumped.pkl')\n",
    "\n",
    "    print(\"TRAIN DATASET DUMPED TO FILE\")\n",
    "\n",
    "print(\"NUMBER OF ENTRIES IN TRAINING DATASET: \", len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1, 10, 300)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for tensor, label in dataset.take(1):\n",
    "    print(tensor.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A shape:  (None, 1, 10, 1)\n",
      "A_adjusted shape:  (None, 1)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1, 10, 300)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 1, 10, 32)    9632        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 1, 10, 32)    9248        ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 1, 10, 32)   128         ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 32)          0           ['batch_normalization_10[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 1, 32)     0           ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 1, 1, 2)      66          ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 1, 1, 32)     96          ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 1, 10, 32)    0           ['batch_normalization_10[0][0]', \n",
      "                                                                  'conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 1, 10, 32)    1056        ['multiply[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 10, 32)    0           ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 1, 10, 32)   128         ['dropout[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 1, 10, 32)    0           ['batch_normalization_11[0][0]', \n",
      "                                                                  'conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 1, 10, 192)   6336        ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 1, 10, 192)  768         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " depthwise_conv2d (DepthwiseCon  (None, 1, 10, 192)  1920        ['batch_normalization_12[0][0]'] \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 1, 10, 192)  768         ['depthwise_conv2d[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 192)         0           ['batch_normalization_13[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1, 1, 192)    0           ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 1, 1, 12)     2316        ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 1, 1, 192)    2496        ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 1, 10, 192)   0           ['batch_normalization_13[0][0]', \n",
      "                                                                  'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 1, 10, 32)    6176        ['multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 1, 10, 32)    0           ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 1, 10, 32)   128         ['dropout_1[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 1, 10, 32)    0           ['batch_normalization_14[0][0]', \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 1, 10, 288)   9504        ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 1, 10, 288)  1152        ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " depthwise_conv2d_1 (DepthwiseC  (None, 1, 10, 288)  2880        ['batch_normalization_16[0][0]'] \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 1, 10, 288)  1152        ['depthwise_conv2d_1[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 288)         0           ['batch_normalization_17[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 1, 1, 288)    0           ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 1, 1, 18)     5202        ['reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 1, 1, 288)    5472        ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 1, 10, 288)   0           ['batch_normalization_17[0][0]', \n",
      "                                                                  'conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 1, 10, 48)    13872       ['multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1, 10, 48)    0           ['conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 1, 10, 48)    1584        ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 1, 10, 48)   192         ['dropout_2[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 1, 10, 48)   192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 1, 10, 48)    0           ['batch_normalization_18[0][0]', \n",
      "                                                                  'batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 1, 10, 288)   14112       ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 1, 10, 288)  1152        ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " depthwise_conv2d_2 (DepthwiseC  (None, 1, 10, 288)  2880        ['batch_normalization_19[0][0]'] \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 1, 10, 288)  1152        ['depthwise_conv2d_2[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4 (Gl  (None, 288)         0           ['batch_normalization_20[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 1, 1, 288)    0           ['global_average_pooling2d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 1, 1, 18)     5202        ['reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 1, 1, 288)    5472        ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 1, 10, 288)   0           ['batch_normalization_20[0][0]', \n",
      "                                                                  'conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 1, 10, 48)    13872       ['multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 1, 10, 48)    0           ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 1, 10, 48)   192         ['dropout_3[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 1, 10, 48)    0           ['batch_normalization_21[0][0]', \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 1, 10, 384)   18816       ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 1, 10, 384)  1536        ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " depthwise_conv2d_3 (DepthwiseC  (None, 1, 10, 384)  3840        ['batch_normalization_23[0][0]'] \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 1, 10, 384)  1536        ['depthwise_conv2d_3[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 384)         0           ['batch_normalization_24[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 1, 1, 384)    0           ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 1, 1, 24)     9240        ['reshape_5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 1, 10, 2)     5402        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 1, 1, 384)    9600        ['conv2d_30[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1, 10, 2)    8           ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 1, 10, 384)   0           ['batch_normalization_24[0][0]', \n",
      "                                                                  'conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 1, 10, 2)     38          ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 1, 10, 64)    24640       ['multiply_4[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 1, 10, 2)    8           ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 1, 10, 64)    0           ['conv2d_32[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 1, 10, 64)    3136        ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 1, 10, 4)     76          ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 1, 10, 64)   256         ['dropout_4[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 1, 10, 64)   256         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 1, 10, 4)    16          ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 1, 10, 64)    0           ['batch_normalization_25[0][0]', \n",
      "                                                                  'batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 1, 10, 4)     148         ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 1, 10, 384)   24960       ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 1, 10, 4)    16          ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 1, 10, 384)  1536        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 1, 10, 8)     296         ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " depthwise_conv2d_4 (DepthwiseC  (None, 1, 10, 384)  3840        ['batch_normalization_26[0][0]'] \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 1, 10, 8)    32          ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 1, 10, 384)  1536        ['depthwise_conv2d_4[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 1, 10, 8)     584         ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6 (Gl  (None, 384)         0           ['batch_normalization_27[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 1, 10, 8)    32          ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 1, 1, 384)    0           ['global_average_pooling2d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 1, 10, 16)    1168        ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 1, 1, 24)     9240        ['reshape_6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 1, 10, 16)   64          ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 1, 1, 384)    9600        ['conv2d_34[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 1, 10, 16)    2320        ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 1, 10, 384)   0           ['batch_normalization_27[0][0]', \n",
      "                                                                  'conv2d_35[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 1, 10, 16)   64          ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 1, 10, 64)    24640       ['multiply_5[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 10, 16)   64          ['batch_normalization_7[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 1, 10, 64)    0           ['conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 1, 10, 16)    272         ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 1, 10, 64)   256         ['dropout_5[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 1, 10, 16)    0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 1, 10, 64)    0           ['batch_normalization_28[0][0]', \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 1, 10, 1)     17          ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 1, 10, 1280)  83200       ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 1, 10, 1)    4           ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 1, 10, 1280)  0           ['conv2d_37[0][0]']              \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1, 10, 1)     0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7 (Gl  (None, 1280)        0           ['dropout_6[0][0]']              \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1)           0           ['activation[0][0]']             \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            1281        ['global_average_pooling2d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1)            0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 1)            0           ['dense[0][0]',                  \n",
      "                                                                  'reshape[0][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 1)           0           ['dense[0][0]',                  \n",
      " da)                                                              'tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 370,072\n",
      "Trainable params: 362,910\n",
      "Non-trainable params: 7,162\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def se_block(input_tensor, ratio=16):\n",
    "    filters = input_tensor.shape[-1]\n",
    "    se = layers.GlobalAveragePooling2D()(input_tensor)\n",
    "    se = layers.Reshape((1, 1, filters))(se)\n",
    "    se = layers.Conv2D(filters // ratio, 1, activation='relu')(se)\n",
    "    se = layers.Conv2D(filters, 1, activation='sigmoid')(se)\n",
    "    return layers.Multiply()([input_tensor, se])\n",
    "\n",
    "def mb_conv1_block(input_tensor, kernel_size=3, filters=16, dropout_rate=0.2):\n",
    "    x = layers.Conv2D(filters, (kernel_size, kernel_size), padding='same')(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = se_block(x)\n",
    "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return layers.Add()([x, input_tensor])\n",
    "\n",
    "def mb_conv6_block(input_tensor, kernel_size=3, filters=16, dropout_rate=0.2):\n",
    "    input_filters = input_tensor.shape[-1]\n",
    "    if input_filters != filters:\n",
    "        shortcut = layers.Conv2D(filters, (1, 1), padding='same')(input_tensor)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "    else:\n",
    "        shortcut = input_tensor\n",
    "\n",
    "    x = layers.Conv2D(filters * 6, (1, 1), padding='same')(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.DepthwiseConv2D((kernel_size, kernel_size), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = se_block(x)\n",
    "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return layers.Add()([x, shortcut])\n",
    "\n",
    "def BasicBlock(input_tensor, c_in, c_out):\n",
    "    x = layers.Conv2D(c_out, (3, 3), padding='same')(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(c_out, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def attention_branch(input_tensor):\n",
    "    x = BasicBlock(input_tensor, 1, 2)\n",
    "    x = BasicBlock(x, 2, 4)\n",
    "    x = BasicBlock(x, 4, 8)\n",
    "    x = BasicBlock(x, 8, 16)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(16, (1, 1), padding='same')(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv2D(1, (1, 1), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    A = layers.Activation('sigmoid')(x)\n",
    "    return A\n",
    "\n",
    "def EfficientNet_A0_with_attention(input_shape=(1, hp.F, hp.T), dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    A = attention_branch(inputs)\n",
    "    print(\"A shape: \", A.shape)\n",
    "    A_adjusted = layers.GlobalAveragePooling2D()(A)\n",
    "    A_adjusted = layers.Reshape((1,))(A_adjusted)\n",
    "    print(\"A_adjusted shape: \", A_adjusted.shape)\n",
    "    x = layers.Conv2D(32, (1, 1), padding='same')(inputs)\n",
    "    x = mb_conv1_block(x, filters=32, dropout_rate=dropout_rate)\n",
    "    x = mb_conv6_block(x, filters=32, dropout_rate=dropout_rate)\n",
    "    x = mb_conv6_block(x, filters=48, dropout_rate=dropout_rate)\n",
    "    x = mb_conv6_block(x, filters=48, dropout_rate=dropout_rate)\n",
    "    x = mb_conv6_block(x, filters=64, dropout_rate=dropout_rate)\n",
    "    x = mb_conv6_block(x, filters=64, dropout_rate=dropout_rate)\n",
    "    x = layers.Conv2D(1280, (1, 1), padding='same')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    R = layers.GlobalAveragePooling2D()(x)\n",
    "    R_output = layers.Dense(1, activation='sigmoid')(R)\n",
    "    combined_output = R_output + R_output * A_adjusted\n",
    "    model = models.Model(inputs, combined_output)\n",
    "    return model\n",
    "\n",
    "# Adding regularization \n",
    "\n",
    "from keras import regularizers, losses\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    bce = losses.binary_crossentropy(y_true, y_pred)\n",
    "    reg = regularizers.l2(0.06)\n",
    "    regularization = tf.reduce_sum(reg(y_pred)) * tf.reduce_max(y_pred)\n",
    "    loss = bce + regularization\n",
    "    return loss\n",
    "\n",
    "\n",
    "# shape: (1xFxT)\n",
    "input_shape = (1, hp.F, hp.T)\n",
    "model = EfficientNet_A0_with_attention(input_shape=input_shape)\n",
    "model.compile(optimizer='adam', loss= custom_loss, metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock (tf.keras.Layer):\n",
    "    def __init__(self,C_in,C_out):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(C_out, (3, 3), padding='same', data_format='channels_first')\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(C_out, (3, 3), padding='same', data_format='channels_first')\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "    def call(self, input):\n",
    "        input = self.conv1(input)\n",
    "        input = self.bn1(input)\n",
    "        input = self.conv2(input)\n",
    "        input = self.bn2(input)\n",
    "        return input\n",
    "    \n",
    "class SEBlock (tf.keras.Model):\n",
    "    def __init__(self, ratio=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.gap = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "class AttentionBranch (tf.keras.Model):\n",
    "    def __init__(self,):\n",
    "        super(AttentionBranch, self).__init__()\n",
    "        self.bb1 = BasicBlock(1,2)\n",
    "        self.bb2 = BasicBlock(2,4)\n",
    "        self.bb3 = BasicBlock(4,8)\n",
    "        self.bb4 = BasicBlock(8,16)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(16, (1, 1), padding='same', data_format='channels_first')\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        self.ab_output_conv = tf.keras.layers.Conv2D(2, (1, 1), padding='same', data_format='channels_first')\n",
    "        self.ab_output_gap = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.ab_output_softmax = tf.keras.layers.Softmax()\n",
    "        self.attention_map_conv = tf.keras.layers.Conv2D(1, (1, 1), padding='same', data_format='channels_first')\n",
    "        self.attention_map_bn = tf.keras.layers.BatchNormalization()\n",
    "        self.attention_map_sigmoid = tf.keras.layers.Activation('sigmoid')\n",
    "    \n",
    "    def call (self, input):\n",
    "        output = self.bb1(input)\n",
    "        output = self.bb2(output)\n",
    "        output = self.bb3(output)\n",
    "        output = self.bb4(output)\n",
    "        output = self.bn1(output)\n",
    "        output = self.conv1(output)\n",
    "        output = self.relu(output)\n",
    "        ab_output =  self.ab_output_conv(output)\n",
    "        ab_output = self.ab_output_gap(ab_output)\n",
    "        ab_output = self.ab_output_softmax(ab_output)\n",
    "        attention_map = self.attention_map_conv(output)\n",
    "        attention_map = self.attention_map_bn(attention_map)\n",
    "        attention_map = self.attention_map_sigmoid(attention_map)\n",
    "        return ab_output, attention_map\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlabels\\n\\none_ctr = 0 \\nzero_ctr = 0 \\n\\nfor i in labels : \\n    if i == 0: \\n        zero_ctr +=1\\n    else : \\n        one_ctr +=1\\n\\nprint(one_ctr , zero_ctr)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "labels\n",
    "\n",
    "one_ctr = 0 \n",
    "zero_ctr = 0 \n",
    "\n",
    "for i in labels : \n",
    "    if i == 0: \n",
    "        zero_ctr +=1\n",
    "    else : \n",
    "        one_ctr +=1\n",
    "\n",
    "print(one_ctr , zero_ctr)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794/794 [==============================] - ETA: 0s - loss: 0.9760 - accuracy: 0.5541"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 44\u001b[0m\n\u001b[0;32m     38\u001b[0m         eer \u001b[38;5;241m=\u001b[39m fpr[np\u001b[38;5;241m.\u001b[39mnanargmin(np\u001b[38;5;241m.\u001b[39mabs(fpr \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m tpr)))]\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEER: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_epochs_training\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mClassWiseAccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\btp\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\btp\\lib\\site-packages\\keras\\engine\\training.py:1624\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m     }\n\u001b[0;32m   1622\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[1;32m-> 1624\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1625\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\btp\\lib\\site-packages\\keras\\callbacks.py:448\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    446\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_logs(logs)\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m--> 448\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 16\u001b[0m, in \u001b[0;36mClassWiseAccuracy.on_epoch_end\u001b[1;34m(self, n_epochs_training, logs)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset:\n\u001b[0;32m     15\u001b[0m     y_true\u001b[38;5;241m.\u001b[39mextend(y\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m---> 16\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     18\u001b[0m         predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m predictions, predictions])\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\btp\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\btp\\lib\\site-packages\\keras\\engine\\training.py:2249\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2247\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_begin()\n\u001b[0;32m   2248\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2250\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   2251\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\btp\\lib\\site-packages\\keras\\engine\\data_adapter.py:1306\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menumerate_epochs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1306\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[0;32m   1307\u001b[0m         data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset)\n\u001b[0;32m   1308\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\btp\\lib\\contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\btp\\lib\\site-packages\\keras\\engine\\data_adapter.py:1327\u001b[0m, in \u001b[0;36mDataHandler._truncate_execution_to_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_truncate_execution_to_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Truncates steps per execution to at most one epoch.\"\"\"\u001b[39;00m\n\u001b[0;32m   1325\u001b[0m     should_truncate \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1326\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1327\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps\n\u001b[0;32m   1328\u001b[0m     )\n\u001b[0;32m   1329\u001b[0m     original_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\btp\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    636\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\btp\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\btp\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "class ClassWiseAccuracy(Callback):\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def on_epoch_end(self, n_epochs_training, logs=None):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for x, y in self.dataset:\n",
    "            y_true.extend(y.numpy())\n",
    "            predictions = self.model.predict(x, verbose=0)\n",
    "            if predictions.shape[1] == 1:\n",
    "                predictions = np.hstack([1 - predictions, predictions])\n",
    "            predictions = softmax(predictions, axis=-1)\n",
    "            y_pred.extend((predictions[:, 1] > 0.5).astype(int))\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "\n",
    "        class_0_indices = np.where(y_true == 0)\n",
    "        class_1_indices = np.where(y_true == 1)\n",
    "\n",
    "        class_0_accuracy = np.mean(y_true[class_0_indices] == y_pred[class_0_indices])\n",
    "        class_1_accuracy = np.mean(y_true[class_1_indices] == y_pred[class_1_indices])\n",
    "\n",
    "        print(f\"Epoch {n_epochs_training + 1}:\")\n",
    "        print(f\"Accuracy for class 0 (bonafide): {class_0_accuracy}\")\n",
    "        print(f\"Accuracy for class 1 (spoofed): {class_1_accuracy}\")\n",
    "\n",
    "        # print EER \n",
    "        from sklearn.metrics import roc_curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "        eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "        print(f\"EER: {eer}\")\n",
    "\n",
    "              \n",
    "\n",
    "\n",
    "model.fit(dataset, epochs= hp.n_epochs_training, callbacks=[ClassWiseAccuracy(dataset)])\n",
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGzCAYAAAAMr0ziAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9xElEQVR4nO3de1zUVeL/8fcAMtxkVFDwgqLoeknDRCFN093YsFxXrAxcFaTMctMsNku3QtOH0cV1cdXNXy2WlSWZZJatqXyzMjVaLxVlaN4zQLEERQNlPr8/ejg1cR0S+Yiv5+PxeTycM+ecOefM4Lz53LAYhmEIAADAxNwaegAAAAA1IbAAAADTI7AAAADTI7AAAADTI7AAAADTI7AAAADTI7AAAADTI7AAAADTI7AAAADTI7DgijR+/HiFhobWqe2sWbNksVgu7oBM5uDBg7JYLHrxxRcv6etu2rRJFotFmzZtcpTV9r2qrzGHhoZq/PjxF7VPAK4jsMBULBZLrbZffqEBv9WWLVs0a9YsnTx5sqGHAqAKHg09AOCXXn75ZafHL730kjZs2FChvHv37r/pdZ5//nnZ7fY6tX300Uc1ffr03/T6qL3f8l7V1pYtW/T4449r/PjxatasmdNzubm5cnPjdzugoRFYYCpjx451erxt2zZt2LChQvmvnTlzRj4+PrV+nSZNmtRpfJLk4eEhDw9+dC6V3/JeXQxWq7VBX/9yUVJSIl9f34YeBhoxfm3AZWfIkCHq2bOntm/fruuvv14+Pj76+9//Lkl66623NGzYMLVp00ZWq1VhYWGaM2eOysvLnfr49XkRF85/mDdvnp577jmFhYXJarWqX79++vTTT53aVnYOi8Vi0eTJk7V69Wr17NlTVqtVV111ldatW1dh/Js2bVLfvn3l5eWlsLAw/b//9/9qfV7MRx99pFGjRql9+/ayWq0KCQnRAw88oLNnz1aYn5+fn44eParY2Fj5+fmpZcuWevDBByusxcmTJzV+/HjZbDY1a9ZMiYmJtTo08r///U8Wi0XLli2r8Nx7770ni8Wid955R5J06NAh/fWvf1XXrl3l7e2tgIAAjRo1SgcPHqzxdSo7h6W2Y/788881fvx4derUSV5eXgoODtYdd9yhEydOOOrMmjVL06ZNkyR17NjRcdjxwtgqO4dl//79GjVqlFq0aCEfHx9de+21Wrt2rVOdC+fjvP7665o7d67atWsnLy8v3XDDDfrmm29qnLcra3by5Ek98MADCg0NldVqVbt27ZSQkKDCwkJHnR9//FGzZs3S7373O3l5eal169a65ZZbtG/fPqfx/vpwa2XnBl34fO3bt08333yzmjZtqjFjxkiq/WdUkr7++mvdfvvtatmypby9vdW1a1c98sgjkqT3339fFotFb775ZoV2r776qiwWi7Zu3VrjOqLx4NdEXJZOnDihm266SfHx8Ro7dqyCgoIkSS+++KL8/PyUnJwsPz8//d///Z9SUlJUXFysZ555psZ+X331VZ06dUp33323LBaLnn76ad1yyy3av39/jb/pb968WZmZmfrrX/+qpk2b6l//+pduvfVWHT58WAEBAZKknTt3aujQoWrdurUef/xxlZeXa/bs2WrZsmWt5r1y5UqdOXNGkyZNUkBAgLKzs7Vw4UJ9++23WrlypVPd8vJyxcTEKCoqSvPmzdPGjRv1j3/8Q2FhYZo0aZIkyTAMjRgxQps3b9Y999yj7t27680331RiYmKNY+nbt686deqk119/vUL9jIwMNW/eXDExMZKkTz/9VFu2bFF8fLzatWungwcP6tlnn9WQIUP01VdfubR3zJUxb9iwQfv371dSUpKCg4P15Zdf6rnnntOXX36pbdu2yWKx6JZbbtGePXv02muv6Z///KcCAwMlqcr3pKCgQAMGDNCZM2d03333KSAgQMuWLdOf//xnvfHGGxo5cqRT/SeffFJubm568MEHVVRUpKefflpjxozRJ598Uu08a7tmp0+f1qBBg7R7927dcccd6tOnjwoLC7VmzRp9++23CgwMVHl5uf70pz8pKytL8fHxmjp1qk6dOqUNGzYoJydHYWFhtV7/C86fP6+YmBgNHDhQ8+bNc4yntp/Rzz//XIMGDVKTJk00ceJEhYaGat++fXr77bc1d+5cDRkyRCEhIVq+fHmFNV2+fLnCwsLUv39/l8eNy5gBmNi9995r/PpjOnjwYEOSsWTJkgr1z5w5U6Hs7rvvNnx8fIwff/zRUZaYmGh06NDB8fjAgQOGJCMgIMD4/vvvHeVvvfWWIcl4++23HWUzZ86sMCZJhqenp/HNN984yj777DNDkrFw4UJH2fDhww0fHx/j6NGjjrK9e/caHh4eFfqsTGXzS01NNSwWi3Ho0CGn+UkyZs+e7VT3mmuuMSIiIhyPV69ebUgynn76aUfZ+fPnjUGDBhmSjBdeeKHa8cyYMcNo0qSJ05qVlpYazZo1M+64445qx71161ZDkvHSSy85yt5//31DkvH+++87zeWX75UrY67sdV977TVDkvHhhx86yp555hlDknHgwIEK9Tt06GAkJiY6Ht9///2GJOOjjz5ylJ06dcro2LGjERoaapSXlzvNpXv37kZpaamj7oIFCwxJxhdffFHhtX6ptmuWkpJiSDIyMzMr1Lfb7YZhGMbSpUsNScb8+fOrrFPZ2hvGzz8bv1zXC5+v6dOn12rclX1Gr7/+eqNp06ZOZb8cj2H89PmyWq3GyZMnHWXHjh0zPDw8jJkzZ1Z4HTRuHBLCZclqtSopKalCube3t+Pfp06dUmFhoQYNGqQzZ87o66+/rrHfuLg4NW/e3PF40KBBkn46BFCT6Ohop99Ur776avn7+zvalpeXa+PGjYqNjVWbNm0c9Tp37qybbrqpxv4l5/mVlJSosLBQAwYMkGEY2rlzZ4X699xzj9PjQYMGOc3l3XfflYeHh2OPiyS5u7trypQptRpPXFyczp07p8zMTEfZ+vXrdfLkScXFxVU67nPnzunEiRPq3LmzmjVrph07dtTqteoy5l++7o8//qjCwkJde+21kuTy6/7y9SMjIzVw4EBHmZ+fnyZOnKiDBw/qq6++cqqflJQkT09Px+PafqZqu2arVq1SeHh4hb0QkhyHGVetWqXAwMBK1+i3XKL/y/egsnFX9Rk9fvy4PvzwQ91xxx1q3759leNJSEhQaWmp3njjDUdZRkaGzp8/X+N5bWh8CCy4LLVt29bpS+CCL7/8UiNHjpTNZpO/v79atmzp+I+tqKioxn5//Z/nhfDyww8/uNz2QvsLbY8dO6azZ8+qc+fOFepVVlaZw4cPa/z48WrRooXjvJTBgwdLqjg/Ly+vCoc1fjke6afzJFq3bi0/Pz+nel27dq3VeMLDw9WtWzdlZGQ4yjIyMhQYGKg//OEPjrKzZ88qJSVFISEhslqtCgwMVMuWLXXy5MlavS+/5MqYv//+e02dOlVBQUHy9vZWy5Yt1bFjR0m1+zxU9fqVvdaFK9cOHTrkVF7Xz1Rt12zfvn3q2bNntX3t27dPXbt2vagni3t4eKhdu3YVymvzGb0Q1moad7du3dSvXz8tX77cUbZ8+XJde+21tf6ZQePBOSy4LP3yt7gLTp48qcGDB8vf31+zZ89WWFiYvLy8tGPHDj388MO1ujTW3d290nLDMOq1bW2Ul5frj3/8o77//ns9/PDD6tatm3x9fXX06FGNHz++wvyqGs/FFhcXp7lz56qwsFBNmzbVmjVrNHr0aKcvxylTpuiFF17Q/fffr/79+8tms8lisSg+Pr5eL1m+/fbbtWXLFk2bNk29e/eWn5+f7Ha7hg4dWu+XSl9Q18/FpV6zqva0/Pok7QusVmuFy71d/YzWRkJCgqZOnapvv/1WpaWl2rZtmxYtWuRyP7j8EVjQaGzatEknTpxQZmamrr/+ekf5gQMHGnBUP2vVqpW8vLwqvUKkNleNfPHFF9qzZ4+WLVumhIQER/mGDRvqPKYOHTooKytLp0+fdtpjkZubW+s+4uLi9Pjjj2vVqlUKCgpScXGx4uPjneq88cYbSkxM1D/+8Q9H2Y8//linG7XVdsw//PCDsrKy9PjjjyslJcVRvnfv3gp9unJYpEOHDpWuz4VDjh06dKh1X9Wp7ZqFhYUpJyen2r7CwsL0ySef6Ny5c1WePH5hz8+v+//1HqPq1PYz2qlTJ0mqcdySFB8fr+TkZL322ms6e/asmjRp4nS4EVcODgmh0bjwm+wvf3MtKyvTv//974YakhN3d3dFR0dr9erV+u677xzl33zzjf773//Wqr3kPD/DMLRgwYI6j+nmm2/W+fPn9eyzzzrKysvLtXDhwlr30b17d/Xq1UsZGRnKyMhQ69atnQLjhbH/eo/CwoULq/zt/WKMubL1kqS0tLQKfV64f0htAtTNN9+s7Oxsp0tqS0pK9Nxzzyk0NFQ9evSo7VSqVds1u/XWW/XZZ59Vevnvhfa33nqrCgsLK90zcaFOhw4d5O7urg8//NDpeVd+fmr7GW3ZsqWuv/56LV26VIcPH650PBcEBgbqpptu0iuvvKLly5dr6NChjiu5cGVhDwsajQEDBqh58+ZKTEzUfffdJ4vFopdffvmiHZK5GGbNmqX169fruuuu06RJk1ReXq5FixapZ8+e2rVrV7Vtu3XrprCwMD344IM6evSo/P39tWrVqlqdX1OV4cOH67rrrtP06dN18OBB9ejRQ5mZmS6f3xEXF6eUlBR5eXnpzjvvrHCo4E9/+pNefvll2Ww29ejRQ1u3btXGjRsdl3vXx5j9/f11/fXX6+mnn9a5c+fUtm1brV+/vtI9bhEREZKkRx55RPHx8WrSpImGDx9e6Y3Qpk+frtdee0033XST7rvvPrVo0ULLli3TgQMHtGrVqot2V9zartm0adP0xhtvaNSoUbrjjjsUERGh77//XmvWrNGSJUsUHh6uhIQEvfTSS0pOTlZ2drYGDRqkkpISbdy4UX/96181YsQI2Ww2jRo1SgsXLpTFYlFYWJjeeecdHTt2rNZjduUz+q9//UsDBw5Unz59NHHiRHXs2FEHDx7U2rVrK/wsJCQk6LbbbpMkzZkzx/XFRONwya9LAlxQ1WXNV111VaX1P/74Y+Paa681vL29jTZt2hgPPfSQ8d5779V4qeyFSzefeeaZCn1KcrqEsqrLmu+9994KbX99SaxhGEZWVpZxzTXXGJ6enkZYWJjxn//8x/jb3/5meHl5VbEKP/vqq6+M6Ohow8/PzwgMDDTuuusux+XTv77s1NfXt0L7ysZ+4sQJY9y4cYa/v79hs9mMcePGGTt37qzVZc0X7N2715BkSDI2b95c4fkffvjBSEpKMgIDAw0/Pz8jJibG+PrrryusT20ua3ZlzN9++60xcuRIo1mzZobNZjNGjRplfPfddxXeU8MwjDlz5hht27Y13NzcnC5xruw93Ldvn3HbbbcZzZo1M7y8vIzIyEjjnXfecapzYS4rV650Kq/sMuHK1HbNLqzH5MmTjbZt2xqenp5Gu3btjMTERKOwsNBR58yZM8YjjzxidOzY0WjSpIkRHBxs3Hbbbca+ffscdY4fP27ceuutho+Pj9G8eXPj7rvvNnJycmr9+TKM2n9GDcMwcnJyHO+Pl5eX0bVrV+Oxxx6r0GdpaanRvHlzw2azGWfPnq123dB4WQzDRL9+Aleo2NhYffnll5WeXwFc6c6fP682bdpo+PDhSk9Pb+jhoIFwDgtwif36FuV79+7Vu+++qyFDhjTMgACTW716tY4fP+50Ii+uPOxhAS6x1q1bO/6+zaFDh/Tss8+qtLRUO3fuVJcuXRp6eIBpfPLJJ/r88881Z84cBQYG1vlmf2gcOOkWuMSGDh2q1157Tfn5+bJarerfv7+eeOIJwgrwK88++6xeeeUV9e7d2+mPL+LKxB4WAABgepzDAgAATI/AAgAATK9RnMNit9v13XffqWnTpr/pL48CAIBLxzAMnTp1Sm3atKnxpouNIrB89913CgkJaehhAACAOjhy5Eilf/37lxpFYGnatKmknybs7+/fwKMBAAC1UVxcrJCQEMf3eHUaRWC5cBjI39+fwAIAwGWmNqdzcNItAAAwPQILAAAwPQILAAAwvUZxDgsAwFwMw9D58+dVXl7e0ENBA3N3d5eHh8dvvu0IgQUAcFGVlZUpLy9PZ86caeihwCR8fHzUunVreXp61rkPAgsA4KKx2+06cOCA3N3d1aZNG3l6enJDzyuYYRgqKyvT8ePHdeDAAXXp0qXGG8RVhcACALhoysrKZLfbFRISIh8fn4YeDkzA29tbTZo00aFDh1RWViYvL6869cNJtwCAi66uv0WjcboYnwc+UQAAwPQILAAAwPQILAAA1JPQ0FClpaXVuv6mTZtksVh08uTJehvT5YrAAgC44lkslmq3WbNm1anfTz/9VBMnTqx1/QEDBigvL082m61Or9eYcZUQAOCKl5eX5/h3RkaGUlJSlJub6yjz8/Nz/NswDJWXl8vDo+av0JYtW7o0Dk9PTwUHB7vU5krBHhYAQL0yDENnys43yGYYRq3GGBwc7NhsNpssFovj8ddff62mTZvqv//9ryIiImS1WrV582bt27dPI0aMUFBQkPz8/NSvXz9t3LjRqd9fHxKyWCz6z3/+o5EjR8rHx0ddunTRmjVrHM//+pDQiy++qGbNmum9995T9+7d5efnp6FDhzoFrPPnz+u+++5Ts2bNFBAQoIcffliJiYmKjY2tcr4nTpzQ6NGj1bZtW/n4+KhXr1567bXXnOrY7XY9/fTT6ty5s6xWq9q3b6+5c+c6nv/22281evRotWjRQr6+vurbt68++eSTWq13XbCHBQBQr86eK1ePlPca5LW/mh0jH8+L81U3ffp0zZs3T506dVLz5s115MgR3XzzzZo7d66sVqteeuklDR8+XLm5uWrfvn2V/Tz++ON6+umn9cwzz2jhwoUaM2aMDh06pBYtWlRa/8yZM5o3b55efvllubm5aezYsXrwwQe1fPlySdJTTz2l5cuX64UXXlD37t21YMECrV69Wr///e+rHMOPP/6oiIgIPfzww/L399fatWs1btw4hYWFKTIyUpI0Y8YMPf/88/rnP/+pgQMHKi8vT19//bUk6fTp0xo8eLDatm2rNWvWKDg4WDt27JDdbq/r8taoTntYFi9erNDQUHl5eSkqKkrZ2dnV1k9LS1PXrl3l7e2tkJAQPfDAA/rxxx9/U58AAFxKs2fP1h//+EeFhYWpRYsWCg8P1913362ePXuqS5cumjNnjsLCwpz2mFRm/PjxGj16tDp37qwnnnhCp0+frvY779y5c1qyZIn69u2rPn36aPLkycrKynI8v3DhQs2YMUMjR45Ut27dtGjRIjVr1qzaMbRt21YPPvigevfurU6dOmnKlCkaOnSoXn/9dUnSqVOntGDBAj399NNKTExUWFiYBg4cqAkTJkiSXn31VR0/flyrV6/WwIED1blzZ91+++3q379/LVfTdS7HzoyMDCUnJ2vJkiWKiopSWlqaYmJilJubq1atWlWo/+qrr2r69OlaunSpBgwYoD179mj8+PGyWCyaP39+nfoEAFw+vJu466vZMQ322hdL3759nR6fPn1as2bN0tq1a5WXl6fz58/r7NmzOnz4cLX9XH311Y5/+/r6yt/fX8eOHauyvo+Pj8LCwhyPW7du7ahfVFSkgoICx14R6ac/NhgREVHt3o7y8nI98cQTev3113X06FGVlZWptLTUcXfi3bt3q7S0VDfccEOl7Xft2qVrrrmmyr1C9cHlwDJ//nzdddddSkpKkiQtWbJEa9eu1dKlSzV9+vQK9bds2aLrrrtOf/nLXyT9dDxv9OjRTse5XO0TAHD5sFgsF+2wTEPy9fV1evzggw9qw4YNmjdvnjp37ixvb2/ddtttKisrq7afJk2aOD22WCzVhovK6tf23JyqPPPMM1qwYIHS0tLUq1cv+fr66v7773eM3dvbu9r2NT1fH1w6JFRWVqbt27crOjr65w7c3BQdHa2tW7dW2mbAgAHavn27Y3fX/v379e677+rmm2+uc5+lpaUqLi522gAAuJQ+/vhjjR8/XiNHjlSvXr0UHBysgwcPXtIx2Gw2BQUF6dNPP3WUlZeXa8eOHdW2+/jjjzVixAiNHTtW4eHh6tSpk/bs2eN4vkuXLvL29nY69PRLV199tXbt2qXvv//+4kykFlwKLIWFhSovL1dQUJBTeVBQkPLz8ytt85e//EWzZ8/WwIED1aRJE4WFhWnIkCH6+9//Xuc+U1NTZbPZHFtISIgr0wAA4Dfr0qWLMjMztWvXLn322Wf6y1/+Uq8nnVZlypQpSk1N1VtvvaXc3FxNnTpVP/zwQ7V/JbtLly7asGGDtmzZot27d+vuu+9WQUGB43kvLy89/PDDeuihh/TSSy9p37592rZtm9LT0yVJo0ePVnBwsGJjY/Xxxx9r//79WrVqVZU7Gi6Ger+sedOmTXriiSf073//Wzt27FBmZqbWrl2rOXPm1LnPGTNmqKioyLEdOXLkIo4YAICazZ8/X82bN9eAAQM0fPhwxcTEqE+fPpd8HA8//LBGjx6thIQE9e/fX35+foqJian2ryI/+uij6tOnj2JiYjRkyBBH+Pilxx57TH/729+UkpKi7t27Ky4uznHujKenp9avX69WrVrp5ptvVq9evfTkk0/K3f3inTP0axbDhQNhZWVl8vHx0RtvvOE0scTERJ08eVJvvfVWhTaDBg3Stddeq2eeecZR9sorr2jixIk6ffq0zp8/73Kfv1ZcXCybzaaioiL5+/vXdjoAgIvsxx9/1IEDB9SxY8dqvzBRf+x2u7p3767bb7/9N+0cuJiq+ly48v3t0h4WT09PRUREOB3TstvtysrKqvJSpjNnzlT4s9IXEphhGHXqEwAA/OTQoUN6/vnntWfPHn3xxReaNGmSDhw44LjYpbFw+bTt5ORkJSYmqm/fvoqMjFRaWppKSkocV/gkJCSobdu2Sk1NlSQNHz5c8+fP1zXXXKOoqCh98803euyxxzR8+HBHcKmpTwAAUDk3Nze9+OKLevDBB2UYhnr27KmNGzeqe/fuDT20i8rlwBIXF6fjx48rJSVF+fn56t27t9atW+c4afbw4cNOe1QeffRRWSwWPfroozp69Khatmyp4cOHO93et6Y+AQBA5UJCQvTxxx839DDqnUvnsJgV57AAgDlwDgsqc8nPYQEAoDYawe/CuIguxueBwAIAuGgu3JX1zJkzDTwSmMmFz8Ov79rrisv/XskAANNwd3dXs2bNHPfr8PHxqfYGZmjcDMPQmTNndOzYMTVr1uw33aeFwAIAuKiCg4Mlqdo/6IcrS7NmzRyfi7oisAAALiqLxaLWrVurVatWOnfuXEMPBw2sSZMmF+UOuAQWAEC9cHd3r9dbtePKwkm3AADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9OoUWBYvXqzQ0FB5eXkpKipK2dnZVdYdMmSILBZLhW3YsGGOOgUFBRo/frzatGkjHx8fDR06VHv37q3L0AAAQCPkcmDJyMhQcnKyZs6cqR07dig8PFwxMTE6duxYpfUzMzOVl5fn2HJycuTu7q5Ro0ZJkgzDUGxsrPbv36+33npLO3fuVIcOHRQdHa2SkpLfNjsAANAoWAzDMFxpEBUVpX79+mnRokWSJLvdrpCQEE2ZMkXTp0+vsX1aWppSUlKUl5cnX19f7dmzR127dlVOTo6uuuoqR5/BwcF64oknNGHChBr7LC4uls1mU1FRkfz9/V2ZDgAAaCCufH+7tIelrKxM27dvV3R09M8duLkpOjpaW7durVUf6enpio+Pl6+vrySptLRUkuTl5eXUp9Vq1ebNmyvto7S0VMXFxU4bAABovFwKLIWFhSovL1dQUJBTeVBQkPLz82tsn52drZycHKe9Jt26dVP79u01Y8YM/fDDDyorK9NTTz2lb7/9Vnl5eZX2k5qaKpvN5thCQkJcmQYAALjMXNKrhNLT09WrVy9FRkY6ypo0aaLMzEzt2bNHLVq0kI+Pj95//33ddNNNcnOrfHgzZsxQUVGRYzty5MilmgIAAGgAHq5UDgwMlLu7uwoKCpzKCwoKFBwcXG3bkpISrVixQrNnz67wXEREhHbt2qWioiKVlZWpZcuWioqKUt++fSvty2q1ymq1ujJ0AABwGXNpD4unp6ciIiKUlZXlKLPb7crKylL//v2rbbty5UqVlpZq7NixVdax2Wxq2bKl9u7dq//9738aMWKEK8MDAACNlEt7WCQpOTlZiYmJ6tu3ryIjI5WWlqaSkhIlJSVJkhISEtS2bVulpqY6tUtPT1dsbKwCAgIq9Lly5Uq1bNlS7du31xdffKGpU6cqNjZWN954Yx2nBQAAGhOXA0tcXJyOHz+ulJQU5efnq3fv3lq3bp3jRNzDhw9XOPckNzdXmzdv1vr16yvtMy8vT8nJySooKFDr1q2VkJCgxx57rA7TAQAAjZHL92ExI+7DAgDA5afe7sMCAADQEAgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9OoUWBYvXqzQ0FB5eXkpKipK2dnZVdYdMmSILBZLhW3YsGGOOqdPn9bkyZPVrl07eXt7q0ePHlqyZEldhgYAABohlwNLRkaGkpOTNXPmTO3YsUPh4eGKiYnRsWPHKq2fmZmpvLw8x5aTkyN3d3eNGjXKUSc5OVnr1q3TK6+8ot27d+v+++/X5MmTtWbNmrrPDAAANBouB5b58+frrrvuUlJSkmNPiI+Pj5YuXVpp/RYtWig4ONixbdiwQT4+Pk6BZcuWLUpMTNSQIUMUGhqqiRMnKjw8vNo9NwAA4MrhUmApKyvT9u3bFR0d/XMHbm6Kjo7W1q1ba9VHenq64uPj5evr6ygbMGCA1qxZo6NHj8owDL3//vvas2ePbrzxxkr7KC0tVXFxsdMGAAAaL5cCS2FhocrLyxUUFORUHhQUpPz8/BrbZ2dnKycnRxMmTHAqX7hwoXr06KF27drJ09NTQ4cO1eLFi3X99ddX2k9qaqpsNptjCwkJcWUaAADgMnNJrxJKT09Xr169FBkZ6VS+cOFCbdu2TWvWrNH27dv1j3/8Q/fee682btxYaT8zZsxQUVGRYzty5MilGD4AAGggHq5UDgwMlLu7uwoKCpzKCwoKFBwcXG3bkpISrVixQrNnz3YqP3v2rP7+97/rzTffdFw5dPXVV2vXrl2aN2+e0+GnC6xWq6xWqytDBwAAlzGX9rB4enoqIiJCWVlZjjK73a6srCz179+/2rYrV65UaWmpxo4d61R+7tw5nTt3Tm5uzkNxd3eX3W53ZXgAAKCRcmkPi/TTJciJiYnq27evIiMjlZaWppKSEiUlJUmSEhIS1LZtW6Wmpjq1S09PV2xsrAICApzK/f39NXjwYE2bNk3e3t7q0KGDPvjgA7300kuaP3/+b5gaAABoLFwOLHFxcTp+/LhSUlKUn5+v3r17a926dY4TcQ8fPlxhb0lubq42b96s9evXV9rnihUrNGPGDI0ZM0bff/+9OnTooLlz5+qee+6pw5QAAEBjYzEMw2joQfxWxcXFstlsKioqkr+/f0MPBwAA1IIr39/8LSEAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6BBYAAGB6dQosixcvVmhoqLy8vBQVFaXs7Owq6w4ZMkQWi6XCNmzYMEedyp63WCx65pln6jI8AADQyLgcWDIyMpScnKyZM2dqx44dCg8PV0xMjI4dO1Zp/czMTOXl5Tm2nJwcubu7a9SoUY46v3w+Ly9PS5culcVi0a233lr3mQEAgEbDYhiG4UqDqKgo9evXT4sWLZIk2e12hYSEaMqUKZo+fXqN7dPS0pSSkqK8vDz5+vpWWic2NlanTp1SVlZWrcZUXFwsm82moqIi+fv7134yAACgwbjy/e3SHpaysjJt375d0dHRP3fg5qbo6Ght3bq1Vn2kp6crPj6+yrBSUFCgtWvX6s4776yyj9LSUhUXFzttAACg8XIpsBQWFqq8vFxBQUFO5UFBQcrPz6+xfXZ2tnJycjRhwoQq6yxbtkxNmzbVLbfcUmWd1NRU2Ww2xxYSElL7SQAAgMvOJb1KKD09Xb169VJkZGSVdZYuXaoxY8bIy8uryjozZsxQUVGRYzty5Eh9DBcAAJiEhyuVAwMD5e7uroKCAqfygoICBQcHV9u2pKREK1as0OzZs6us89FHHyk3N1cZGRnV9mW1WmW1Wms/cAAAcFlzaQ+Lp6enIiIinE6GtdvtysrKUv/+/attu3LlSpWWlmrs2LFV1klPT1dERITCw8NdGRYAAGjkXD4klJycrOeff17Lli3T7t27NWnSJJWUlCgpKUmSlJCQoBkzZlRol56ertjYWAUEBFTab3FxsVauXFnt+S0AAODK5NIhIUmKi4vT8ePHlZKSovz8fPXu3Vvr1q1znIh7+PBhubk556Dc3Fxt3rxZ69evr7LfFStWyDAMjR492tUhAQCARs7l+7CYEfdhAQDg8lNv92EBAABoCAQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgegQWAABgenUKLIsXL1ZoaKi8vLwUFRWl7OzsKusOGTJEFoulwjZs2DCnert379af//xn2Ww2+fr6ql+/fjp8+HBdhgcAABoZlwNLRkaGkpOTNXPmTO3YsUPh4eGKiYnRsWPHKq2fmZmpvLw8x5aTkyN3d3eNGjXKUWffvn0aOHCgunXrpk2bNunzzz/XY489Ji8vr7rPDAAANBoWwzAMVxpERUWpX79+WrRokSTJbrcrJCREU6ZM0fTp02tsn5aWppSUFOXl5cnX11eSFB8fryZNmujll1+uwxSk4uJi2Ww2FRUVyd/fv059AACAS8uV72+X9rCUlZVp+/btio6O/rkDNzdFR0dr69atteojPT1d8fHxjrBit9u1du1a/e53v1NMTIxatWqlqKgorV69uso+SktLVVxc7LQBAIDGy6XAUlhYqPLycgUFBTmVBwUFKT8/v8b22dnZysnJ0YQJExxlx44d0+nTp/Xkk09q6NChWr9+vUaOHKlbbrlFH3zwQaX9pKamymazObaQkBBXpgEAAC4zl/QqofT0dPXq1UuRkZGOMrvdLkkaMWKEHnjgAfXu3VvTp0/Xn/70Jy1ZsqTSfmbMmKGioiLHduTIkUsyfgAA0DBcCiyBgYFyd3dXQUGBU3lBQYGCg4OrbVtSUqIVK1bozjvvrNCnh4eHevTo4VTevXv3Kq8Sslqt8vf3d9oAAEDj5VJg8fT0VEREhLKyshxldrtdWVlZ6t+/f7VtV65cqdLSUo0dO7ZCn/369VNubq5T+Z49e9ShQwdXhgcAABopD1cbJCcnKzExUX379lVkZKTS0tJUUlKipKQkSVJCQoLatm2r1NRUp3bp6emKjY1VQEBAhT6nTZumuLg4XX/99fr973+vdevW6e2339amTZvqNisAANCouBxY4uLidPz4caWkpCg/P1+9e/fWunXrHCfiHj58WG5uzjtucnNztXnzZq1fv77SPkeOHKklS5YoNTVV9913n7p27apVq1Zp4MCBdZgSAABobFy+D4sZcR8WAAAuP/V2HxYAAICGQGABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmV6fAsnjxYoWGhsrLy0tRUVHKzs6usu6QIUNksVgqbMOGDXPUGT9+fIXnhw4dWpehAQCARsjD1QYZGRlKTk7WkiVLFBUVpbS0NMXExCg3N1etWrWqUD8zM1NlZWWOxydOnFB4eLhGjRrlVG/o0KF64YUXHI+tVqurQwMAAI2Uy3tY5s+fr7vuuktJSUnq0aOHlixZIh8fHy1durTS+i1atFBwcLBj27Bhg3x8fCoEFqvV6lSvefPmdZsRAABodFwKLGVlZdq+fbuio6N/7sDNTdHR0dq6dWut+khPT1d8fLx8fX2dyjdt2qRWrVqpa9eumjRpkk6cOFFlH6WlpSouLnbaAABA4+VSYCksLFR5ebmCgoKcyoOCgpSfn19j++zsbOXk5GjChAlO5UOHDtVLL72krKwsPfXUU/rggw900003qby8vNJ+UlNTZbPZHFtISIgr0wAAAJcZl89h+S3S09PVq1cvRUZGOpXHx8c7/t2rVy9dffXVCgsL06ZNm3TDDTdU6GfGjBlKTk52PC4uLia0AADQiLm0hyUwMFDu7u4qKChwKi8oKFBwcHC1bUtKSrRixQrdeeedNb5Op06dFBgYqG+++abS561Wq/z9/Z02AADQeLkUWDw9PRUREaGsrCxHmd1uV1ZWlvr3719t25UrV6q0tFRjx46t8XW+/fZbnThxQq1bt3ZleAAAoJFy+Sqh5ORkPf/881q2bJl2796tSZMmqaSkRElJSZKkhIQEzZgxo0K79PR0xcbGKiAgwKn89OnTmjZtmrZt26aDBw8qKytLI0aMUOfOnRUTE1PHaQEAgMbE5XNY4uLidPz4caWkpCg/P1+9e/fWunXrHCfiHj58WG5uzjkoNzdXmzdv1vr16yv05+7urs8//1zLli3TyZMn1aZNG914442aM2cO92IBAACSJIthGEZDD+K3Ki4uls1mU1FREeezAABwmXDl+5u/JQQAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyPwAIAAEyvToFl8eLFCg0NlZeXl6KiopSdnV1l3SFDhshisVTYhg0bVmn9e+65RxaLRWlpaXUZGgAAaIRcDiwZGRlKTk7WzJkztWPHDoWHhysmJkbHjh2rtH5mZqby8vIcW05Ojtzd3TVq1KgKdd98801t27ZNbdq0cX0mAACg0XI5sMyfP1933XWXkpKS1KNHDy1ZskQ+Pj5aunRppfVbtGih4OBgx7Zhwwb5+PhUCCxHjx7VlClTtHz5cjVp0qRuswEAAI2SS4GlrKxM27dvV3R09M8duLkpOjpaW7durVUf6enpio+Pl6+vr6PMbrdr3LhxmjZtmq666qoa+ygtLVVxcbHTBgAAGi+XAkthYaHKy8sVFBTkVB4UFKT8/Pwa22dnZysnJ0cTJkxwKn/qqafk4eGh++67r1bjSE1Nlc1mc2whISG1nwQAALjsXNKrhNLT09WrVy9FRkY6yrZv364FCxboxRdflMViqVU/M2bMUFFRkWM7cuRIfQ0ZAACYgEuBJTAwUO7u7iooKHAqLygoUHBwcLVtS0pKtGLFCt15551O5R999JGOHTum9u3by8PDQx4eHjp06JD+9re/KTQ0tNK+rFar/P39nTYAANB4uRRYPD09FRERoaysLEeZ3W5XVlaW+vfvX23blStXqrS0VGPHjnUqHzdunD7//HPt2rXLsbVp00bTpk3Te++958rwAABAI+XhaoPk5GQlJiaqb9++ioyMVFpamkpKSpSUlCRJSkhIUNu2bZWamurULj09XbGxsQoICHAqDwgIqFDWpEkTBQcHq2vXrq4ODwAANEIuB5a4uDgdP35cKSkpys/PV+/evbVu3TrHibiHDx+Wm5vzjpvc3Fxt3rxZ69evvzijBgAAVxSLYRhGQw/ityouLpbNZlNRURHnswAAcJlw5fubvyUEAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMr06BZfHixQoNDZWXl5eioqKUnZ1dZd0hQ4bIYrFU2IYNG+aoM2vWLHXr1k2+vr5q3ry5oqOj9cknn9RlaAAAoBFyObBkZGQoOTlZM2fO1I4dOxQeHq6YmBgdO3as0vqZmZnKy8tzbDk5OXJ3d9eoUaMcdX73u99p0aJF+uKLL7R582aFhobqxhtv1PHjx+s+MwAA0GhYDMMwXGkQFRWlfv36adGiRZIku92ukJAQTZkyRdOnT6+xfVpamlJSUpSXlydfX99K6xQXF8tms2njxo264YYbauzzQv2ioiL5+/u7Mh0AANBAXPn+dmkPS1lZmbZv367o6OifO3BzU3R0tLZu3VqrPtLT0xUfH19lWCkrK9Nzzz0nm82m8PDwSuuUlpaquLjYaQMAAI2XS4GlsLBQ5eXlCgoKcioPCgpSfn5+je2zs7OVk5OjCRMmVHjunXfekZ+fn7y8vPTPf/5TGzZsUGBgYKX9pKamymazObaQkBBXpgEAAC4zl/QqofT0dPXq1UuRkZEVnvv973+vXbt2acuWLRo6dKhuv/32Ks+LmTFjhoqKihzbkSNH6nvoAACgAbkUWAIDA+Xu7q6CggKn8oKCAgUHB1fbtqSkRCtWrNCdd95Z6fO+vr7q3Lmzrr32WqWnp8vDw0Pp6emV1rVarfL393faAABA4+VSYPH09FRERISysrIcZXa7XVlZWerfv3+1bVeuXKnS0lKNHTu2Vq9lt9tVWlrqyvAAAEAj5eFqg+TkZCUmJqpv376KjIxUWlqaSkpKlJSUJElKSEhQ27ZtlZqa6tQuPT1dsbGxCggIcCovKSnR3Llz9ec//1mtW7dWYWGhFi9erKNHjzpd+gwAAK5cLgeWuLg4HT9+XCkpKcrPz1fv3r21bt06x4m4hw8flpub846b3Nxcbd68WevXr6/Qn7u7u77++mstW7ZMhYWFCggIUL9+/fTRRx/pqquuquO0AABAY+LyfVjMiPuwAABw+am3+7AAAAA0BAILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPY+GHsDFYBiGJKm4uLiBRwIAAGrrwvf2he/x6jSKwHLq1ClJUkhISAOPBAAAuOrUqVOy2WzV1rEYtYk1Jme32/Xdd9+padOmslgsDT2cBldcXKyQkBAdOXJE/v7+DT2cRot1vjRY50uHtb40WOefGYahU6dOqU2bNnJzq/4slUaxh8XNzU3t2rVr6GGYjr+//xX/w3ApsM6XBut86bDWlwbr/JOa9qxcwEm3AADA9AgsAADA9AgsjZDVatXMmTNltVobeiiNGut8abDOlw5rfWmwznXTKE66BQAAjRt7WAAAgOkRWAAAgOkRWAAAgOkRWAAAgOkRWAAAgOkRWC4TixcvVmhoqLy8vBQVFaXs7Owq6547d06zZ89WWFiYvLy8FB4ernXr1lWod/ToUY0dO1YBAQHy9vZWr1699L///a8+p2F6F3udy8vL9dhjj6ljx47y9vZWWFiY5syZU6s/9NVYffjhhxo+fLjatGkji8Wi1atX19hm06ZN6tOnj6xWqzp37qwXX3yxQh1X3rsrQX2sc2pqqvr166emTZuqVatWio2NVW5ubv1M4DJRX5/nC5588klZLBbdf//9F23Mly0DprdixQrD09PTWLp0qfHll18ad911l9GsWTOjoKCg0voPPfSQ0aZNG2Pt2rXGvn37jH//+9+Gl5eXsWPHDked77//3ujQoYMxfvx445NPPjH2799vvPfee8Y333xzqaZlOvWxznPnzjUCAgKMd955xzhw4ICxcuVKw8/Pz1iwYMGlmpbpvPvuu8YjjzxiZGZmGpKMN998s9r6+/fvN3x8fIzk5GTjq6++MhYuXGi4u7sb69atc9Rx9b27EtTHOsfExBgvvPCCkZOTY+zatcu4+eabjfbt2xunT5+u59mYV32s8wXZ2dlGaGiocfXVVxtTp06tnwlcRggsl4HIyEjj3nvvdTwuLy832rRpY6SmplZav3Xr1saiRYucym655RZjzJgxjscPP/ywMXDgwPoZ8GWqPtZ52LBhxh133FFtnStZbf6Df+ihh4yrrrrKqSwuLs6IiYlxPHb1vbvSXKx1/rVjx44ZkowPPvjgYgzzsncx1/nUqVNGly5djA0bNhiDBw8msBiGwSEhkysrK9P27dsVHR3tKHNzc1N0dLS2bt1aaZvS0lJ5eXk5lXl7e2vz5s2Ox2vWrFHfvn01atQotWrVStdcc42ef/75+pnEZaC+1nnAgAHKysrSnj17JEmfffaZNm/erJtuuqkeZtE4bd261el9kaSYmBjH+1KX9w4V1bTOlSkqKpIktWjRol7H1pjUdp3vvfdeDRs2rELdKxmBxeQKCwtVXl6uoKAgp/KgoCDl5+dX2iYmJkbz58/X3r17ZbfbtWHDBmVmZiovL89RZ//+/Xr22WfVpUsXvffee5o0aZLuu+8+LVu2rF7nY1b1tc7Tp09XfHy8unXrpiZNmuiaa67R/fffrzFjxtTrfBqT/Pz8St+X4uJinT17tk7vHSqqaZ1/zW636/7779d1112nnj17XqphXvZqs84rVqzQjh07lJqa2hBDNC0CSyO0YMECdenSRd26dZOnp6cmT56spKQkubn9/Hbb7Xb16dNHTzzxhK655hpNnDhRd911l5YsWdKAI7+81GadX3/9dS1fvlyvvvqqduzYoWXLlmnevHlXbDBE43HvvfcqJydHK1asaOihNCpHjhzR1KlTtXz58gp7cK90BBaTCwwMlLu7uwoKCpzKCwoKFBwcXGmbli1bavXq1SopKdGhQ4f09ddfy8/PT506dXLUad26tXr06OHUrnv37jp8+PDFn8RloL7Wedq0aY69LL169dK4ceP0wAMP8JuTC4KDgyt9X/z9/eXt7V2n9w4V1bTOvzR58mS98847ev/999WuXbtLOczLXk3rvH37dh07dkx9+vSRh4eHPDw89MEHH+hf//qXPDw8VF5e3kAjb3gEFpPz9PRURESEsrKyHGV2u11ZWVnq379/tW29vLzUtm1bnT9/XqtWrdKIESMcz1133XUVLkfcs2ePOnTocHEncJmor3U+c+aM0x4XSXJ3d5fdbr+4E2jE+vfv7/S+SNKGDRsc78tvee/ws5rWWZIMw9DkyZP15ptv6v/+7//UsWPHSz3My15N63zDDTfoiy++0K5duxxb3759NWbMGO3atUvu7u4NMWxzaOizflGzFStWGFar1XjxxReNr776ypg4caLRrFkzIz8/3zAMwxg3bpwxffp0R/1t27YZq1atMvbt22d8+OGHxh/+8AejY8eOxg8//OCok52dbXh4eBhz58419u7dayxfvtzw8fExXnnllUs9PdOoj3VOTEw02rZt67isOTMz0wgMDDQeeuihSz090zh16pSxc+dOY+fOnYYkY/78+cbOnTuNQ4cOGYZhGNOnTzfGjRvnqH/hMtBp06YZu3fvNhYvXlzpZc3VvXdXovpY50mTJhk2m83YtGmTkZeX59jOnDlzyednFvWxzr/GVUI/IbBcJhYuXGi0b9/e8PT0NCIjI41t27Y5nhs8eLCRmJjoeLxp0yaje/fuhtVqNQICAoxx48YZR48erdDn22+/bfTs2dOwWq1Gt27djOeee+5STMXULvY6FxcXG1OnTjXat29veHl5GZ06dTIeeeQRo7S09FJNyXTef/99Q1KF7cLaJiYmGoMHD67Qpnfv3oanp6fRqVMn44UXXqjQb3Xv3ZWoPta5sv4kVfp+XCnq6/P8SwSWn1gM4wq+5SYAALgscA4LAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwPQILAAAwvf8PgD3GVF3ulWoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    # val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    # val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, label='Training acc')\n",
    "    # plt.plot(epochs, val_acc, label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, label='Training loss')\n",
    "    # plt.plot(epochs, val_loss, label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(model.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from pkl\n",
    "\n",
    "# model = tf.keras.models.load_model('model.keras')\n",
    "\n",
    "\n",
    "# model.evaluate(dataset_val)\n",
    "# predictions = model.predict(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING OF THE MODEL IS DONE!\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING OF THE MODEL IS DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
